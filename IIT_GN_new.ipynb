{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EEYoqD-66fy0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcl-MO7Y3GGa",
        "outputId": "cb587a03-b6da-4f94-b34e-56daf1fd341e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HqLZG5dS6qiv"
      },
      "outputs": [],
      "source": [
        "data = pd.read_excel('/content/drive/MyDrive/IIT-G/inputdata.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Jl8OJKA76_Nd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c2ae3e9c-93b8-4081-c1c2-193d0676db47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    defect_density  no_of_defects  index_removed   roff_rv        ron_rv\n",
              "0         0.023444              1            216  0.000007  8.804207e-09\n",
              "1         0.023553              2            217  0.005373  3.050072e-08\n",
              "2         0.023662              3            218  0.000663  3.682850e-08\n",
              "3         0.023770              4            219  0.000256  5.926848e-06\n",
              "4         0.023879              5            220  0.000407  2.387368e-05\n",
              "5         0.023987              6            221  0.000647  1.113548e-04\n",
              "6         0.024096              7            222  0.000007  8.804207e-09\n",
              "7         0.024204              8            223  0.005373  3.050072e-08\n",
              "8         0.024313              9            224  0.000663  3.682850e-08\n",
              "9         0.024421             10            225  0.000256  5.926848e-06\n",
              "10        0.024530             11            226  0.000407  2.387368e-05\n",
              "11        0.024638             12            227  0.000647  1.113548e-04\n",
              "12        0.024747             13            228  0.000007  8.804207e-09\n",
              "13        0.024855             14            229  0.005373  3.050072e-08\n",
              "14        0.024964             15            230  0.000663  3.682850e-08\n",
              "15        0.025073             16            231  0.000256  5.926848e-06\n",
              "16        0.025181             17            232  0.000407  2.387368e-05\n",
              "17        0.025290             18            233  0.000647  1.113548e-04\n",
              "18        0.025398             19            234  0.000007  8.804207e-09\n",
              "19        0.025507             20            235  0.005373  3.050072e-08\n",
              "20        0.025615             21            236  0.000663  3.682850e-08\n",
              "21        0.025724             22            237  0.000256  5.926848e-06\n",
              "22        0.025832             23            238  0.000407  2.387368e-05\n",
              "23        0.025941             24            239  0.000647  1.113548e-04\n",
              "24        0.028654             25            264  0.000007  8.804207e-09\n",
              "25        0.028763             26            265  0.005373  3.050072e-08\n",
              "26        0.028871             27            266  0.000663  3.682850e-08\n",
              "27        0.028980             28            267  0.000256  5.926848e-06\n",
              "28        0.029088             29            268  0.000407  2.387368e-05\n",
              "29        0.029197             30            269  0.000647  1.113548e-04\n",
              "30        0.029306             31            270  0.000007  8.804207e-09\n",
              "31        0.029414             32            271  0.005373  3.050072e-08\n",
              "32        0.029523             33            272  0.000663  3.682850e-08\n",
              "33        0.029631             34            273  0.000256  5.926848e-06\n",
              "34        0.029740             35            274  0.000407  2.387368e-05\n",
              "35        0.029848             36            275  0.000647  1.113548e-04\n",
              "36        0.029957             37            276  0.000007  8.804207e-09\n",
              "37        0.030065             38            277  0.005373  3.050072e-08\n",
              "38        0.030174             39            278  0.000663  3.682850e-08\n",
              "39        0.030282             40            279  0.000256  5.926848e-06\n",
              "40        0.030391             41            280  0.000407  2.387368e-05\n",
              "41        0.030499             42            281  0.000647  1.113548e-04\n",
              "42        0.030608             43            282  0.000007  8.804207e-09\n",
              "43        0.030717             44            283  0.005373  3.050072e-08\n",
              "44        0.030825             45            284  0.000663  3.682850e-08\n",
              "45        0.030934             46            285  0.000256  5.926848e-06\n",
              "46        0.031042             47            286  0.000407  2.387368e-05\n",
              "47        0.031151             48            287  0.000647  1.113548e-04"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10725530-d6a2-4e7f-92af-ab505ec9ce66\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>defect_density</th>\n",
              "      <th>no_of_defects</th>\n",
              "      <th>index_removed</th>\n",
              "      <th>roff_rv</th>\n",
              "      <th>ron_rv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.023444</td>\n",
              "      <td>1</td>\n",
              "      <td>216</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>8.804207e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.023553</td>\n",
              "      <td>2</td>\n",
              "      <td>217</td>\n",
              "      <td>0.005373</td>\n",
              "      <td>3.050072e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.023662</td>\n",
              "      <td>3</td>\n",
              "      <td>218</td>\n",
              "      <td>0.000663</td>\n",
              "      <td>3.682850e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.023770</td>\n",
              "      <td>4</td>\n",
              "      <td>219</td>\n",
              "      <td>0.000256</td>\n",
              "      <td>5.926848e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.023879</td>\n",
              "      <td>5</td>\n",
              "      <td>220</td>\n",
              "      <td>0.000407</td>\n",
              "      <td>2.387368e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.023987</td>\n",
              "      <td>6</td>\n",
              "      <td>221</td>\n",
              "      <td>0.000647</td>\n",
              "      <td>1.113548e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.024096</td>\n",
              "      <td>7</td>\n",
              "      <td>222</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>8.804207e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.024204</td>\n",
              "      <td>8</td>\n",
              "      <td>223</td>\n",
              "      <td>0.005373</td>\n",
              "      <td>3.050072e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.024313</td>\n",
              "      <td>9</td>\n",
              "      <td>224</td>\n",
              "      <td>0.000663</td>\n",
              "      <td>3.682850e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.024421</td>\n",
              "      <td>10</td>\n",
              "      <td>225</td>\n",
              "      <td>0.000256</td>\n",
              "      <td>5.926848e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.024530</td>\n",
              "      <td>11</td>\n",
              "      <td>226</td>\n",
              "      <td>0.000407</td>\n",
              "      <td>2.387368e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.024638</td>\n",
              "      <td>12</td>\n",
              "      <td>227</td>\n",
              "      <td>0.000647</td>\n",
              "      <td>1.113548e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.024747</td>\n",
              "      <td>13</td>\n",
              "      <td>228</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>8.804207e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.024855</td>\n",
              "      <td>14</td>\n",
              "      <td>229</td>\n",
              "      <td>0.005373</td>\n",
              "      <td>3.050072e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.024964</td>\n",
              "      <td>15</td>\n",
              "      <td>230</td>\n",
              "      <td>0.000663</td>\n",
              "      <td>3.682850e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.025073</td>\n",
              "      <td>16</td>\n",
              "      <td>231</td>\n",
              "      <td>0.000256</td>\n",
              "      <td>5.926848e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.025181</td>\n",
              "      <td>17</td>\n",
              "      <td>232</td>\n",
              "      <td>0.000407</td>\n",
              "      <td>2.387368e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.025290</td>\n",
              "      <td>18</td>\n",
              "      <td>233</td>\n",
              "      <td>0.000647</td>\n",
              "      <td>1.113548e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.025398</td>\n",
              "      <td>19</td>\n",
              "      <td>234</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>8.804207e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.025507</td>\n",
              "      <td>20</td>\n",
              "      <td>235</td>\n",
              "      <td>0.005373</td>\n",
              "      <td>3.050072e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.025615</td>\n",
              "      <td>21</td>\n",
              "      <td>236</td>\n",
              "      <td>0.000663</td>\n",
              "      <td>3.682850e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.025724</td>\n",
              "      <td>22</td>\n",
              "      <td>237</td>\n",
              "      <td>0.000256</td>\n",
              "      <td>5.926848e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.025832</td>\n",
              "      <td>23</td>\n",
              "      <td>238</td>\n",
              "      <td>0.000407</td>\n",
              "      <td>2.387368e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.025941</td>\n",
              "      <td>24</td>\n",
              "      <td>239</td>\n",
              "      <td>0.000647</td>\n",
              "      <td>1.113548e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.028654</td>\n",
              "      <td>25</td>\n",
              "      <td>264</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>8.804207e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.028763</td>\n",
              "      <td>26</td>\n",
              "      <td>265</td>\n",
              "      <td>0.005373</td>\n",
              "      <td>3.050072e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.028871</td>\n",
              "      <td>27</td>\n",
              "      <td>266</td>\n",
              "      <td>0.000663</td>\n",
              "      <td>3.682850e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.028980</td>\n",
              "      <td>28</td>\n",
              "      <td>267</td>\n",
              "      <td>0.000256</td>\n",
              "      <td>5.926848e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.029088</td>\n",
              "      <td>29</td>\n",
              "      <td>268</td>\n",
              "      <td>0.000407</td>\n",
              "      <td>2.387368e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.029197</td>\n",
              "      <td>30</td>\n",
              "      <td>269</td>\n",
              "      <td>0.000647</td>\n",
              "      <td>1.113548e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.029306</td>\n",
              "      <td>31</td>\n",
              "      <td>270</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>8.804207e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.029414</td>\n",
              "      <td>32</td>\n",
              "      <td>271</td>\n",
              "      <td>0.005373</td>\n",
              "      <td>3.050072e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.029523</td>\n",
              "      <td>33</td>\n",
              "      <td>272</td>\n",
              "      <td>0.000663</td>\n",
              "      <td>3.682850e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.029631</td>\n",
              "      <td>34</td>\n",
              "      <td>273</td>\n",
              "      <td>0.000256</td>\n",
              "      <td>5.926848e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.029740</td>\n",
              "      <td>35</td>\n",
              "      <td>274</td>\n",
              "      <td>0.000407</td>\n",
              "      <td>2.387368e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.029848</td>\n",
              "      <td>36</td>\n",
              "      <td>275</td>\n",
              "      <td>0.000647</td>\n",
              "      <td>1.113548e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.029957</td>\n",
              "      <td>37</td>\n",
              "      <td>276</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>8.804207e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.030065</td>\n",
              "      <td>38</td>\n",
              "      <td>277</td>\n",
              "      <td>0.005373</td>\n",
              "      <td>3.050072e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.030174</td>\n",
              "      <td>39</td>\n",
              "      <td>278</td>\n",
              "      <td>0.000663</td>\n",
              "      <td>3.682850e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.030282</td>\n",
              "      <td>40</td>\n",
              "      <td>279</td>\n",
              "      <td>0.000256</td>\n",
              "      <td>5.926848e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.030391</td>\n",
              "      <td>41</td>\n",
              "      <td>280</td>\n",
              "      <td>0.000407</td>\n",
              "      <td>2.387368e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.030499</td>\n",
              "      <td>42</td>\n",
              "      <td>281</td>\n",
              "      <td>0.000647</td>\n",
              "      <td>1.113548e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.030608</td>\n",
              "      <td>43</td>\n",
              "      <td>282</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>8.804207e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.030717</td>\n",
              "      <td>44</td>\n",
              "      <td>283</td>\n",
              "      <td>0.005373</td>\n",
              "      <td>3.050072e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.030825</td>\n",
              "      <td>45</td>\n",
              "      <td>284</td>\n",
              "      <td>0.000663</td>\n",
              "      <td>3.682850e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.030934</td>\n",
              "      <td>46</td>\n",
              "      <td>285</td>\n",
              "      <td>0.000256</td>\n",
              "      <td>5.926848e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.031042</td>\n",
              "      <td>47</td>\n",
              "      <td>286</td>\n",
              "      <td>0.000407</td>\n",
              "      <td>2.387368e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.031151</td>\n",
              "      <td>48</td>\n",
              "      <td>287</td>\n",
              "      <td>0.000647</td>\n",
              "      <td>1.113548e-04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10725530-d6a2-4e7f-92af-ab505ec9ce66')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-10725530-d6a2-4e7f-92af-ab505ec9ce66 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-10725530-d6a2-4e7f-92af-ab505ec9ce66');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c3f692c9-dca3-46a5-a51f-7453952c6c6f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c3f692c9-dca3-46a5-a51f-7453952c6c6f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c3f692c9-dca3-46a5-a51f-7453952c6c6f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_cdddd005-7daa-4392-a686-82d1d077784a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_cdddd005-7daa-4392-a686-82d1d077784a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 48,\n  \"fields\": [\n    {\n      \"column\": \"defect_density\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0027398128352373397,\n        \"min\": 0.023444429216893,\n        \"max\": 0.0311506999317051,\n        \"num_unique_values\": 48,\n        \"samples\": [\n          0.0289799194486594,\n          0.0303909267626391,\n          0.0288713804245072\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"no_of_defects\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 1,\n        \"max\": 48,\n        \"num_unique_values\": 48,\n        \"samples\": [\n          28,\n          41,\n          27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"index_removed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25,\n        \"min\": 216,\n        \"max\": 287,\n        \"num_unique_values\": 48,\n        \"samples\": [\n          267,\n          280,\n          266\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roff_rv\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0018884189079215927,\n        \"min\": 7.18116144058856e-06,\n        \"max\": 0.00537337589369173,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          7.18116144058856e-06,\n          0.00537337589369173,\n          0.00064720272876936\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ron_rv\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.059262021110898e-05,\n        \"min\": 8.80420741713041e-09,\n        \"max\": 0.000111354848017854,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          8.80420741713041e-09,\n          3.05007199370124e-08,\n          0.000111354848017854\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "o1eFh4l04OtR"
      },
      "outputs": [],
      "source": [
        "# data = data.fillna(0) # NAN = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "U3R2JeXC40hC"
      },
      "outputs": [],
      "source": [
        "# data = data.replace('Au', 1)\n",
        "# data = data.replace('W', 2)\n",
        "# data = data.replace('Mo', 3)\n",
        "# data = data.replace('Sn', 4)\n",
        "# data = data.replace('Pt', 5)\n",
        "# data = data.replace('Ti', 6)\n",
        "# data = data.replace('H-BN', 11)\n",
        "# data = data.replace('MoS2', 12)\n",
        "# data = data.replace('MoSe2', 13)\n",
        "# data = data.replace('PdSe2', 14)\n",
        "\n",
        "# # Au = 1, W = 2, Mo = 3, Sn = 4, Pt = 5, Ti = 6,\n",
        "# # H-BN = 11, MoS2 = 12, MoSe2 = 13,PdSe2 = 14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QQLMGsRb6_w6"
      },
      "outputs": [],
      "source": [
        "x = data[['defect_density','no_of_defects']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QiCjZAfO7GVa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0cf2abdc-5a58-4705-a272-dcf45865258b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    defect_density  no_of_defects\n",
              "0         0.023444              1\n",
              "1         0.023553              2\n",
              "2         0.023662              3\n",
              "3         0.023770              4\n",
              "4         0.023879              5\n",
              "5         0.023987              6\n",
              "6         0.024096              7\n",
              "7         0.024204              8\n",
              "8         0.024313              9\n",
              "9         0.024421             10\n",
              "10        0.024530             11\n",
              "11        0.024638             12\n",
              "12        0.024747             13\n",
              "13        0.024855             14\n",
              "14        0.024964             15\n",
              "15        0.025073             16\n",
              "16        0.025181             17\n",
              "17        0.025290             18\n",
              "18        0.025398             19\n",
              "19        0.025507             20\n",
              "20        0.025615             21\n",
              "21        0.025724             22\n",
              "22        0.025832             23\n",
              "23        0.025941             24\n",
              "24        0.028654             25\n",
              "25        0.028763             26\n",
              "26        0.028871             27\n",
              "27        0.028980             28\n",
              "28        0.029088             29\n",
              "29        0.029197             30\n",
              "30        0.029306             31\n",
              "31        0.029414             32\n",
              "32        0.029523             33\n",
              "33        0.029631             34\n",
              "34        0.029740             35\n",
              "35        0.029848             36\n",
              "36        0.029957             37\n",
              "37        0.030065             38\n",
              "38        0.030174             39\n",
              "39        0.030282             40\n",
              "40        0.030391             41\n",
              "41        0.030499             42\n",
              "42        0.030608             43\n",
              "43        0.030717             44\n",
              "44        0.030825             45\n",
              "45        0.030934             46\n",
              "46        0.031042             47\n",
              "47        0.031151             48"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d5466a3-c426-4aa4-b213-00f674841f7e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>defect_density</th>\n",
              "      <th>no_of_defects</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.023444</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.023553</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.023662</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.023770</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.023879</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.023987</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.024096</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.024204</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.024313</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.024421</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.024530</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.024638</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.024747</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.024855</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.024964</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.025073</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.025181</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.025290</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.025398</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.025507</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.025615</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.025724</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.025832</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.025941</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.028654</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.028763</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.028871</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.028980</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.029088</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.029197</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.029306</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.029414</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.029523</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.029631</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.029740</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.029848</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.029957</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.030065</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.030174</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.030282</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.030391</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.030499</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.030608</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.030717</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.030825</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.030934</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.031042</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.031151</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d5466a3-c426-4aa4-b213-00f674841f7e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4d5466a3-c426-4aa4-b213-00f674841f7e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4d5466a3-c426-4aa4-b213-00f674841f7e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-81799777-8c8f-4e3f-8802-a968c032aa98\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-81799777-8c8f-4e3f-8802-a968c032aa98')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-81799777-8c8f-4e3f-8802-a968c032aa98 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_7aa9f1ae-758c-4449-89ec-a940af9aa3c9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('x')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7aa9f1ae-758c-4449-89ec-a940af9aa3c9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('x');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x",
              "summary": "{\n  \"name\": \"x\",\n  \"rows\": 48,\n  \"fields\": [\n    {\n      \"column\": \"defect_density\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0027398128352373397,\n        \"min\": 0.023444429216893,\n        \"max\": 0.0311506999317051,\n        \"num_unique_values\": 48,\n        \"samples\": [\n          0.0289799194486594,\n          0.0303909267626391,\n          0.0288713804245072\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"no_of_defects\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 1,\n        \"max\": 48,\n        \"num_unique_values\": 48,\n        \"samples\": [\n          28,\n          41,\n          27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "szObJtz_715s"
      },
      "outputs": [],
      "source": [
        "y = data[['ron_rv','roff_rv']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "L6CFWTuv8Hah",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "512ee5d8-8717-40e3-a394-36cec883a1cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          ron_rv   roff_rv\n",
              "0   8.804207e-09  0.000007\n",
              "1   3.050072e-08  0.005373\n",
              "2   3.682850e-08  0.000663\n",
              "3   5.926848e-06  0.000256\n",
              "4   2.387368e-05  0.000407\n",
              "5   1.113548e-04  0.000647\n",
              "6   8.804207e-09  0.000007\n",
              "7   3.050072e-08  0.005373\n",
              "8   3.682850e-08  0.000663\n",
              "9   5.926848e-06  0.000256\n",
              "10  2.387368e-05  0.000407\n",
              "11  1.113548e-04  0.000647\n",
              "12  8.804207e-09  0.000007\n",
              "13  3.050072e-08  0.005373\n",
              "14  3.682850e-08  0.000663\n",
              "15  5.926848e-06  0.000256\n",
              "16  2.387368e-05  0.000407\n",
              "17  1.113548e-04  0.000647\n",
              "18  8.804207e-09  0.000007\n",
              "19  3.050072e-08  0.005373\n",
              "20  3.682850e-08  0.000663\n",
              "21  5.926848e-06  0.000256\n",
              "22  2.387368e-05  0.000407\n",
              "23  1.113548e-04  0.000647\n",
              "24  8.804207e-09  0.000007\n",
              "25  3.050072e-08  0.005373\n",
              "26  3.682850e-08  0.000663\n",
              "27  5.926848e-06  0.000256\n",
              "28  2.387368e-05  0.000407\n",
              "29  1.113548e-04  0.000647\n",
              "30  8.804207e-09  0.000007\n",
              "31  3.050072e-08  0.005373\n",
              "32  3.682850e-08  0.000663\n",
              "33  5.926848e-06  0.000256\n",
              "34  2.387368e-05  0.000407\n",
              "35  1.113548e-04  0.000647\n",
              "36  8.804207e-09  0.000007\n",
              "37  3.050072e-08  0.005373\n",
              "38  3.682850e-08  0.000663\n",
              "39  5.926848e-06  0.000256\n",
              "40  2.387368e-05  0.000407\n",
              "41  1.113548e-04  0.000647\n",
              "42  8.804207e-09  0.000007\n",
              "43  3.050072e-08  0.005373\n",
              "44  3.682850e-08  0.000663\n",
              "45  5.926848e-06  0.000256\n",
              "46  2.387368e-05  0.000407\n",
              "47  1.113548e-04  0.000647"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ffda46a-9a22-4f03-ac48-7fb9c2177797\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ron_rv</th>\n",
              "      <th>roff_rv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.804207e-09</td>\n",
              "      <td>0.000007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.050072e-08</td>\n",
              "      <td>0.005373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.682850e-08</td>\n",
              "      <td>0.000663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.926848e-06</td>\n",
              "      <td>0.000256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.387368e-05</td>\n",
              "      <td>0.000407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.113548e-04</td>\n",
              "      <td>0.000647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>8.804207e-09</td>\n",
              "      <td>0.000007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3.050072e-08</td>\n",
              "      <td>0.005373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3.682850e-08</td>\n",
              "      <td>0.000663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5.926848e-06</td>\n",
              "      <td>0.000256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2.387368e-05</td>\n",
              "      <td>0.000407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.113548e-04</td>\n",
              "      <td>0.000647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>8.804207e-09</td>\n",
              "      <td>0.000007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3.050072e-08</td>\n",
              "      <td>0.005373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>3.682850e-08</td>\n",
              "      <td>0.000663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>5.926848e-06</td>\n",
              "      <td>0.000256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2.387368e-05</td>\n",
              "      <td>0.000407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.113548e-04</td>\n",
              "      <td>0.000647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>8.804207e-09</td>\n",
              "      <td>0.000007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3.050072e-08</td>\n",
              "      <td>0.005373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>3.682850e-08</td>\n",
              "      <td>0.000663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>5.926848e-06</td>\n",
              "      <td>0.000256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2.387368e-05</td>\n",
              "      <td>0.000407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1.113548e-04</td>\n",
              "      <td>0.000647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>8.804207e-09</td>\n",
              "      <td>0.000007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>3.050072e-08</td>\n",
              "      <td>0.005373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>3.682850e-08</td>\n",
              "      <td>0.000663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>5.926848e-06</td>\n",
              "      <td>0.000256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2.387368e-05</td>\n",
              "      <td>0.000407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1.113548e-04</td>\n",
              "      <td>0.000647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>8.804207e-09</td>\n",
              "      <td>0.000007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>3.050072e-08</td>\n",
              "      <td>0.005373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>3.682850e-08</td>\n",
              "      <td>0.000663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>5.926848e-06</td>\n",
              "      <td>0.000256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>2.387368e-05</td>\n",
              "      <td>0.000407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>1.113548e-04</td>\n",
              "      <td>0.000647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>8.804207e-09</td>\n",
              "      <td>0.000007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>3.050072e-08</td>\n",
              "      <td>0.005373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>3.682850e-08</td>\n",
              "      <td>0.000663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>5.926848e-06</td>\n",
              "      <td>0.000256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>2.387368e-05</td>\n",
              "      <td>0.000407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>1.113548e-04</td>\n",
              "      <td>0.000647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>8.804207e-09</td>\n",
              "      <td>0.000007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>3.050072e-08</td>\n",
              "      <td>0.005373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>3.682850e-08</td>\n",
              "      <td>0.000663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>5.926848e-06</td>\n",
              "      <td>0.000256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>2.387368e-05</td>\n",
              "      <td>0.000407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>1.113548e-04</td>\n",
              "      <td>0.000647</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ffda46a-9a22-4f03-ac48-7fb9c2177797')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4ffda46a-9a22-4f03-ac48-7fb9c2177797 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4ffda46a-9a22-4f03-ac48-7fb9c2177797');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-645e293e-fe4a-43ec-bb29-c10c7c430d2c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-645e293e-fe4a-43ec-bb29-c10c7c430d2c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-645e293e-fe4a-43ec-bb29-c10c7c430d2c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_664d0de7-5fac-4e0c-96e8-7ca12575cae3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('y')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_664d0de7-5fac-4e0c-96e8-7ca12575cae3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('y');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "y",
              "summary": "{\n  \"name\": \"y\",\n  \"rows\": 48,\n  \"fields\": [\n    {\n      \"column\": \"ron_rv\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.059262021110898e-05,\n        \"min\": 8.80420741713041e-09,\n        \"max\": 0.000111354848017854,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          8.80420741713041e-09,\n          3.05007199370124e-08,\n          0.000111354848017854\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roff_rv\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0018884189079215927,\n        \"min\": 7.18116144058856e-06,\n        \"max\": 0.00537337589369173,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          7.18116144058856e-06,\n          0.00537337589369173,\n          0.00064720272876936\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gVq5fDxP8JUd"
      },
      "outputs": [],
      "source": [
        "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "# x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nP9JroVj8UYg"
      },
      "outputs": [],
      "source": [
        "# print(x_train.shape)\n",
        "# print(y_train.shape)\n",
        "# print(x_val.shape)\n",
        "# print(y_val.shape)\n",
        "# print(x_test.shape)\n",
        "# print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QtNF6WblKgXN"
      },
      "outputs": [],
      "source": [
        "# y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NwOAIwZH8zop"
      },
      "outputs": [],
      "source": [
        "# print(type(x_train))\n",
        "# print(type(y_train))\n",
        "# print(type(x_val))\n",
        "# print(type(y_val))\n",
        "# print(type(x_test))\n",
        "# print(type(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "eAS4zOB4Fhhm"
      },
      "outputs": [],
      "source": [
        "# x_train = x_train.to_numpy()\n",
        "# y_train = y_train.to_numpy()\n",
        "# x_test = x_test.to_numpy()\n",
        "# y_test = y_test.to_numpy()\n",
        "# x_val = x_val.to_numpy()\n",
        "# y_val = y_val.to_numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ii_zjMtc81O0"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(256, activation='relu', input_shape=(2,)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(8, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='linear')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['mean_absolute_error'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-iMMjA59LqV",
        "outputId": "a91d59c1-0ed7-4144-866c-c6c9ff299821"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 256)               768       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 128)               512       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 64)                256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 32)                128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 87978 (343.66 KB)\n",
            "Trainable params: 87530 (341.91 KB)\n",
            "Non-trainable params: 448 (1.75 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install visualkeras\n",
        "# import visualkeras\n",
        "# from tensorflow.python.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, ZeroPadding2D\n",
        "# from collections import defaultdict\n",
        "# from PIL import ImageFont"
      ],
      "metadata": {
        "id": "j0gT5LdFbxrS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# color_map = defaultdict(dict)\n",
        "# color_map[Conv2D]['fill'] = 'orange'\n",
        "# color_map[ZeroPadding2D]['fill'] = 'gray'\n",
        "# color_map[Dropout]['fill'] = 'pink'\n",
        "# color_map[MaxPooling2D]['fill'] = 'red'\n",
        "# color_map[Dense]['fill'] = 'green'\n",
        "# color_map[Flatten]['fill'] = 'teal'\n",
        "\n",
        "# visualkeras.layered_view(model, legend=True)"
      ],
      "metadata": {
        "id": "nWgl_e6yY9r6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExLVkRVl9PmX",
        "outputId": "e9887cb9-3bdd-428b-c5b2-46346ed0dfce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 6s 18ms/step - loss: 0.2731 - mean_absolute_error: 0.2731\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3168 - mean_absolute_error: 0.3168\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3183 - mean_absolute_error: 0.3183\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2329 - mean_absolute_error: 0.2329\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2397 - mean_absolute_error: 0.2397\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.1990 - mean_absolute_error: 0.1990\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2071 - mean_absolute_error: 0.2071\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2100 - mean_absolute_error: 0.2100\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.1727 - mean_absolute_error: 0.1727\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1507 - mean_absolute_error: 0.1507\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1455 - mean_absolute_error: 0.1455\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.1358 - mean_absolute_error: 0.1358\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.1025 - mean_absolute_error: 0.1025\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.1255 - mean_absolute_error: 0.1255\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1181 - mean_absolute_error: 0.1181\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1107 - mean_absolute_error: 0.1107\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1146 - mean_absolute_error: 0.1146\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1079 - mean_absolute_error: 0.1079\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0801 - mean_absolute_error: 0.0801\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1075 - mean_absolute_error: 0.1075\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0777 - mean_absolute_error: 0.0777\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0608 - mean_absolute_error: 0.0608\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0826 - mean_absolute_error: 0.0826\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0920 - mean_absolute_error: 0.0920\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0712 - mean_absolute_error: 0.0712\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.0682 - mean_absolute_error: 0.0682\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.0686 - mean_absolute_error: 0.0686\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0488 - mean_absolute_error: 0.0488\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0466 - mean_absolute_error: 0.0466\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0442 - mean_absolute_error: 0.0442\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0549 - mean_absolute_error: 0.0549\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0594 - mean_absolute_error: 0.0594\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0461 - mean_absolute_error: 0.0461\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0342 - mean_absolute_error: 0.0342\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0511 - mean_absolute_error: 0.0511\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0321 - mean_absolute_error: 0.0321\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0183 - mean_absolute_error: 0.0183\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0272 - mean_absolute_error: 0.0272\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0374 - mean_absolute_error: 0.0374\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0158 - mean_absolute_error: 0.0158\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0191 - mean_absolute_error: 0.0191\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0314 - mean_absolute_error: 0.0314\n",
            "Epoch 43/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0237 - mean_absolute_error: 0.0237\n",
            "Epoch 44/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0102 - mean_absolute_error: 0.0102\n",
            "Epoch 45/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0076 - mean_absolute_error: 0.0076\n",
            "Epoch 46/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0090 - mean_absolute_error: 0.0090\n",
            "Epoch 47/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0090 - mean_absolute_error: 0.0090\n",
            "Epoch 48/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0122 - mean_absolute_error: 0.0122\n",
            "Epoch 49/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0293 - mean_absolute_error: 0.0293\n",
            "Epoch 50/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0172 - mean_absolute_error: 0.0172\n",
            "Epoch 51/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0172 - mean_absolute_error: 0.0172\n",
            "Epoch 52/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0170 - mean_absolute_error: 0.0170\n",
            "Epoch 53/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0126 - mean_absolute_error: 0.0126\n",
            "Epoch 54/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0210 - mean_absolute_error: 0.0210\n",
            "Epoch 55/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0103 - mean_absolute_error: 0.0103\n",
            "Epoch 56/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0170 - mean_absolute_error: 0.0170\n",
            "Epoch 57/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0105 - mean_absolute_error: 0.0105\n",
            "Epoch 58/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0037 - mean_absolute_error: 0.0037\n",
            "Epoch 59/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0030 - mean_absolute_error: 0.0030\n",
            "Epoch 60/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0100 - mean_absolute_error: 0.0100\n",
            "Epoch 61/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0066 - mean_absolute_error: 0.0066\n",
            "Epoch 62/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.0058 - mean_absolute_error: 0.0058\n",
            "Epoch 63/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0160 - mean_absolute_error: 0.0160\n",
            "Epoch 64/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0052 - mean_absolute_error: 0.0052\n",
            "Epoch 65/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0036 - mean_absolute_error: 0.0036\n",
            "Epoch 66/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0045 - mean_absolute_error: 0.0045\n",
            "Epoch 67/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0052 - mean_absolute_error: 0.0052\n",
            "Epoch 68/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0054 - mean_absolute_error: 0.0054\n",
            "Epoch 69/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0099 - mean_absolute_error: 0.0099\n",
            "Epoch 70/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0049 - mean_absolute_error: 0.0049\n",
            "Epoch 71/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0018 - mean_absolute_error: 0.0018\n",
            "Epoch 72/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0023 - mean_absolute_error: 0.0023\n",
            "Epoch 73/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0028 - mean_absolute_error: 0.0028\n",
            "Epoch 74/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0193 - mean_absolute_error: 0.0193\n",
            "Epoch 75/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0091 - mean_absolute_error: 0.0091\n",
            "Epoch 76/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0081 - mean_absolute_error: 0.0081\n",
            "Epoch 77/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0064 - mean_absolute_error: 0.0064\n",
            "Epoch 78/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0027 - mean_absolute_error: 0.0027\n",
            "Epoch 79/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0015 - mean_absolute_error: 0.0015\n",
            "Epoch 80/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0097 - mean_absolute_error: 0.0097\n",
            "Epoch 81/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0029 - mean_absolute_error: 0.0029\n",
            "Epoch 82/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.0066 - mean_absolute_error: 0.0066\n",
            "Epoch 83/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6.2457e-04 - mean_absolute_error: 6.2457e-04\n",
            "Epoch 84/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0080 - mean_absolute_error: 0.0080\n",
            "Epoch 85/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0013 - mean_absolute_error: 0.0013\n",
            "Epoch 86/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0036 - mean_absolute_error: 0.0036\n",
            "Epoch 87/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0060 - mean_absolute_error: 0.0060\n",
            "Epoch 88/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0030 - mean_absolute_error: 0.0030\n",
            "Epoch 89/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0012 - mean_absolute_error: 0.0012   \n",
            "Epoch 90/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0062 - mean_absolute_error: 0.0062\n",
            "Epoch 91/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0102 - mean_absolute_error: 0.0102\n",
            "Epoch 92/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0022 - mean_absolute_error: 0.0022\n",
            "Epoch 93/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0043 - mean_absolute_error: 0.0043\n",
            "Epoch 94/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0023 - mean_absolute_error: 0.0023\n",
            "Epoch 95/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.0025 - mean_absolute_error: 0.0025   \n",
            "Epoch 96/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0050 - mean_absolute_error: 0.0050\n",
            "Epoch 97/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0027 - mean_absolute_error: 0.0027\n",
            "Epoch 98/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0018 - mean_absolute_error: 0.0018   \n",
            "Epoch 99/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 9.9271e-04 - mean_absolute_error: 9.9271e-04\n",
            "Epoch 100/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 6.0675e-04 - mean_absolute_error: 6.0675e-04\n",
            "Epoch 101/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.0040 - mean_absolute_error: 0.0040\n",
            "Epoch 102/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.7068e-04 - mean_absolute_error: 5.7068e-04\n",
            "Epoch 103/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0037 - mean_absolute_error: 0.0037\n",
            "Epoch 104/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.4387e-04 - mean_absolute_error: 5.4387e-04\n",
            "Epoch 105/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 6.1624e-04 - mean_absolute_error: 6.1624e-04\n",
            "Epoch 106/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 8.7240e-04 - mean_absolute_error: 8.7240e-04\n",
            "Epoch 107/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0067 - mean_absolute_error: 0.0067\n",
            "Epoch 108/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0025 - mean_absolute_error: 0.0025\n",
            "Epoch 109/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.4509e-04 - mean_absolute_error: 5.4509e-04\n",
            "Epoch 110/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.5003e-04 - mean_absolute_error: 5.5003e-04\n",
            "Epoch 111/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0028 - mean_absolute_error: 0.0028\n",
            "Epoch 112/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.8804e-04 - mean_absolute_error: 5.8804e-04\n",
            "Epoch 113/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0092 - mean_absolute_error: 0.0092\n",
            "Epoch 114/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 8.4158e-04 - mean_absolute_error: 8.4158e-04\n",
            "Epoch 115/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 6.9228e-04 - mean_absolute_error: 6.9228e-04\n",
            "Epoch 116/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.0027 - mean_absolute_error: 0.0027\n",
            "Epoch 117/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 5.4686e-04 - mean_absolute_error: 5.4686e-04\n",
            "Epoch 118/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.4987e-04 - mean_absolute_error: 5.4987e-04\n",
            "Epoch 119/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0083 - mean_absolute_error: 0.0083   \n",
            "Epoch 120/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0017 - mean_absolute_error: 0.0017\n",
            "Epoch 121/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0016 - mean_absolute_error: 0.0016\n",
            "Epoch 122/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.1978e-04 - mean_absolute_error: 5.1978e-04\n",
            "Epoch 123/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0010 - mean_absolute_error: 0.0010   \n",
            "Epoch 124/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0023 - mean_absolute_error: 0.0023\n",
            "Epoch 125/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 8.4058e-04 - mean_absolute_error: 8.4058e-04\n",
            "Epoch 126/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.0012 - mean_absolute_error: 0.0012   \n",
            "Epoch 127/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0025 - mean_absolute_error: 0.0025\n",
            "Epoch 128/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0024 - mean_absolute_error: 0.0024   \n",
            "Epoch 129/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 9.0787e-04 - mean_absolute_error: 9.0787e-04\n",
            "Epoch 130/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 6.1973e-04 - mean_absolute_error: 6.1973e-04\n",
            "Epoch 131/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 6.9526e-04 - mean_absolute_error: 6.9526e-04\n",
            "Epoch 132/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0032 - mean_absolute_error: 0.0032\n",
            "Epoch 133/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 5.7607e-04 - mean_absolute_error: 5.7607e-04\n",
            "Epoch 134/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0017 - mean_absolute_error: 0.0017\n",
            "Epoch 135/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.0060 - mean_absolute_error: 0.0060\n",
            "Epoch 136/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 6.4910e-04 - mean_absolute_error: 6.4910e-04\n",
            "Epoch 137/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0035 - mean_absolute_error: 0.0035   \n",
            "Epoch 138/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0015 - mean_absolute_error: 0.0015\n",
            "Epoch 139/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0011 - mean_absolute_error: 0.0011\n",
            "Epoch 140/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0045 - mean_absolute_error: 0.0045\n",
            "Epoch 141/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0011 - mean_absolute_error: 0.0011\n",
            "Epoch 142/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 8.2144e-04 - mean_absolute_error: 8.2144e-04\n",
            "Epoch 143/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.2358e-04 - mean_absolute_error: 5.2358e-04\n",
            "Epoch 144/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0061 - mean_absolute_error: 0.0061\n",
            "Epoch 145/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.5250e-04 - mean_absolute_error: 5.5250e-04\n",
            "Epoch 146/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 8.2353e-04 - mean_absolute_error: 8.2353e-04\n",
            "Epoch 147/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0015 - mean_absolute_error: 0.0015\n",
            "Epoch 148/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.6176e-04 - mean_absolute_error: 5.6176e-04\n",
            "Epoch 149/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0011 - mean_absolute_error: 0.0011\n",
            "Epoch 150/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.7489e-04 - mean_absolute_error: 5.7489e-04\n",
            "Epoch 151/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 6.8410e-04 - mean_absolute_error: 6.8410e-04\n",
            "Epoch 152/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0014 - mean_absolute_error: 0.0014\n",
            "Epoch 153/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 6.4751e-04 - mean_absolute_error: 6.4751e-04\n",
            "Epoch 154/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0013 - mean_absolute_error: 0.0013\n",
            "Epoch 155/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 7.7956e-04 - mean_absolute_error: 7.7956e-04\n",
            "Epoch 156/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0023 - mean_absolute_error: 0.0023\n",
            "Epoch 157/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 8.1238e-04 - mean_absolute_error: 8.1238e-04\n",
            "Epoch 158/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0024 - mean_absolute_error: 0.0024   \n",
            "Epoch 159/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.4529e-04 - mean_absolute_error: 5.4529e-04\n",
            "Epoch 160/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0021 - mean_absolute_error: 0.0021\n",
            "Epoch 161/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 9.6427e-04 - mean_absolute_error: 9.6427e-04\n",
            "Epoch 162/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 5.7603e-04 - mean_absolute_error: 5.7603e-04\n",
            "Epoch 163/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 5.5695e-04 - mean_absolute_error: 5.5695e-04\n",
            "Epoch 164/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 6.0812e-04 - mean_absolute_error: 6.0812e-04\n",
            "Epoch 165/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0028 - mean_absolute_error: 0.0028\n",
            "Epoch 166/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.7445e-04 - mean_absolute_error: 5.7445e-04\n",
            "Epoch 167/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.6643e-04 - mean_absolute_error: 5.6643e-04\n",
            "Epoch 168/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0019 - mean_absolute_error: 0.0019\n",
            "Epoch 169/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9.8323e-04 - mean_absolute_error: 9.8323e-04\n",
            "Epoch 170/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0011 - mean_absolute_error: 0.0011   \n",
            "Epoch 171/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.3325e-04 - mean_absolute_error: 5.3325e-04\n",
            "Epoch 172/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 6.3374e-04 - mean_absolute_error: 6.3374e-04\n",
            "Epoch 173/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0025 - mean_absolute_error: 0.0025   \n",
            "Epoch 174/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0026 - mean_absolute_error: 0.0026\n",
            "Epoch 175/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6.0956e-04 - mean_absolute_error: 6.0956e-04\n",
            "Epoch 176/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.2557e-04 - mean_absolute_error: 7.2557e-04\n",
            "Epoch 177/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.1782e-04 - mean_absolute_error: 7.1782e-04\n",
            "Epoch 178/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 6.6183e-04 - mean_absolute_error: 6.6183e-04\n",
            "Epoch 179/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0064 - mean_absolute_error: 0.0064\n",
            "Epoch 180/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6.9360e-04 - mean_absolute_error: 6.9360e-04\n",
            "Epoch 181/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.9992e-04 - mean_absolute_error: 7.9992e-04\n",
            "Epoch 182/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 6.3839e-04 - mean_absolute_error: 6.3839e-04\n",
            "Epoch 183/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6.2730e-04 - mean_absolute_error: 6.2730e-04\n",
            "Epoch 184/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.2636e-04 - mean_absolute_error: 7.2636e-04\n",
            "Epoch 185/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.0217e-04 - mean_absolute_error: 6.0217e-04\n",
            "Epoch 186/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0010 - mean_absolute_error: 0.0010\n",
            "Epoch 187/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 5.7685e-04 - mean_absolute_error: 5.7685e-04\n",
            "Epoch 188/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0015 - mean_absolute_error: 0.0015   \n",
            "Epoch 189/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 5.7986e-04 - mean_absolute_error: 5.7986e-04\n",
            "Epoch 190/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0020 - mean_absolute_error: 0.0020\n",
            "Epoch 191/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.6374e-04 - mean_absolute_error: 5.6374e-04\n",
            "Epoch 192/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0018 - mean_absolute_error: 0.0018\n",
            "Epoch 193/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0019 - mean_absolute_error: 0.0019\n",
            "Epoch 194/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 5.5409e-04 - mean_absolute_error: 5.5409e-04\n",
            "Epoch 195/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0036 - mean_absolute_error: 0.0036\n",
            "Epoch 196/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 5.3437e-04 - mean_absolute_error: 5.3437e-04\n",
            "Epoch 197/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 5.2351e-04 - mean_absolute_error: 5.2351e-04\n",
            "Epoch 198/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0023 - mean_absolute_error: 0.0023   \n",
            "Epoch 199/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0039 - mean_absolute_error: 0.0039\n",
            "Epoch 200/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0012 - mean_absolute_error: 0.0012   \n",
            "Epoch 201/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.2091e-04 - mean_absolute_error: 5.2091e-04\n",
            "Epoch 202/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.2102e-04 - mean_absolute_error: 5.2102e-04\n",
            "Epoch 203/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 5.3977e-04 - mean_absolute_error: 5.3977e-04\n",
            "Epoch 204/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.2654e-04 - mean_absolute_error: 5.2654e-04\n",
            "Epoch 205/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.3689e-04 - mean_absolute_error: 5.3689e-04\n",
            "Epoch 206/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 5.8085e-04 - mean_absolute_error: 5.8085e-04\n",
            "Epoch 207/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.6487e-04 - mean_absolute_error: 5.6487e-04\n",
            "Epoch 208/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0012 - mean_absolute_error: 0.0012\n",
            "Epoch 209/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.8394e-04 - mean_absolute_error: 5.8394e-04\n",
            "Epoch 210/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.0018 - mean_absolute_error: 0.0018   \n",
            "Epoch 211/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 6.1902e-04 - mean_absolute_error: 6.1902e-04\n",
            "Epoch 212/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.0022 - mean_absolute_error: 0.0022\n",
            "Epoch 213/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 8.0165e-04 - mean_absolute_error: 8.0165e-04\n",
            "Epoch 214/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0013 - mean_absolute_error: 0.0013   \n",
            "Epoch 215/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 5.3825e-04 - mean_absolute_error: 5.3825e-04\n",
            "Epoch 216/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0013 - mean_absolute_error: 0.0013\n",
            "Epoch 217/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.5477e-04 - mean_absolute_error: 5.5477e-04\n",
            "Epoch 218/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0024 - mean_absolute_error: 0.0024   \n",
            "Epoch 219/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.7350e-04 - mean_absolute_error: 5.7350e-04\n",
            "Epoch 220/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0019 - mean_absolute_error: 0.0019   \n",
            "Epoch 221/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 5.4889e-04 - mean_absolute_error: 5.4889e-04\n",
            "Epoch 222/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 5.5984e-04 - mean_absolute_error: 5.5984e-04\n",
            "Epoch 223/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.6309e-04 - mean_absolute_error: 5.6309e-04\n",
            "Epoch 224/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.7141e-04 - mean_absolute_error: 5.7141e-04\n",
            "Epoch 225/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.6815e-04 - mean_absolute_error: 5.6815e-04\n",
            "Epoch 226/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0016 - mean_absolute_error: 0.0016\n",
            "Epoch 227/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 5.7314e-04 - mean_absolute_error: 5.7314e-04\n",
            "Epoch 228/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 8.2261e-04 - mean_absolute_error: 8.2261e-04\n",
            "Epoch 229/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.3068e-04 - mean_absolute_error: 5.3068e-04\n",
            "Epoch 230/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 5.5047e-04 - mean_absolute_error: 5.5047e-04\n",
            "Epoch 231/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0014 - mean_absolute_error: 0.0014\n",
            "Epoch 232/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0044 - mean_absolute_error: 0.0044\n",
            "Epoch 233/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 5.3356e-04 - mean_absolute_error: 5.3356e-04\n",
            "Epoch 234/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.7126e-04 - mean_absolute_error: 5.7126e-04\n",
            "Epoch 235/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 7.1515e-04 - mean_absolute_error: 7.1515e-04\n",
            "Epoch 236/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.7850e-04 - mean_absolute_error: 5.7850e-04\n",
            "Epoch 237/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0016 - mean_absolute_error: 0.0016\n",
            "Epoch 238/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 9.3644e-04 - mean_absolute_error: 9.3644e-04\n",
            "Epoch 239/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 6.5632e-04 - mean_absolute_error: 6.5632e-04\n",
            "Epoch 240/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 6.2589e-04 - mean_absolute_error: 6.2589e-04\n",
            "Epoch 241/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0036 - mean_absolute_error: 0.0036\n",
            "Epoch 242/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 6.3187e-04 - mean_absolute_error: 6.3187e-04\n",
            "Epoch 243/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0020 - mean_absolute_error: 0.0020   \n",
            "Epoch 244/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0013 - mean_absolute_error: 0.0013   \n",
            "Epoch 245/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.7241e-04 - mean_absolute_error: 5.7241e-04\n",
            "Epoch 246/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 6.2312e-04 - mean_absolute_error: 6.2312e-04\n",
            "Epoch 247/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 8.9422e-04 - mean_absolute_error: 8.9422e-04\n",
            "Epoch 248/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 6.2437e-04 - mean_absolute_error: 6.2437e-04\n",
            "Epoch 249/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 5.4697e-04 - mean_absolute_error: 5.4697e-04\n",
            "Epoch 250/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 6.6112e-04 - mean_absolute_error: 6.6112e-04\n",
            "Epoch 251/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 5.5890e-04 - mean_absolute_error: 5.5890e-04\n",
            "Epoch 252/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 6.4604e-04 - mean_absolute_error: 6.4604e-04\n",
            "Epoch 253/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.5915e-04 - mean_absolute_error: 5.5915e-04\n",
            "Epoch 254/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 7.0171e-04 - mean_absolute_error: 7.0171e-04\n",
            "Epoch 255/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.8965e-04 - mean_absolute_error: 5.8965e-04\n",
            "Epoch 256/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0014 - mean_absolute_error: 0.0014   \n",
            "Epoch 257/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 7.2692e-04 - mean_absolute_error: 7.2692e-04\n",
            "Epoch 258/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 7.6729e-04 - mean_absolute_error: 7.6729e-04\n",
            "Epoch 259/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.0012 - mean_absolute_error: 0.0012\n",
            "Epoch 260/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 6.0921e-04 - mean_absolute_error: 6.0921e-04\n",
            "Epoch 261/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6.3568e-04 - mean_absolute_error: 6.3568e-04\n",
            "Epoch 262/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 6.4944e-04 - mean_absolute_error: 6.4944e-04\n",
            "Epoch 263/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 6.8834e-04 - mean_absolute_error: 6.8834e-04\n",
            "Epoch 264/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.5741e-04 - mean_absolute_error: 5.5741e-04\n",
            "Epoch 265/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 5.9225e-04 - mean_absolute_error: 5.9225e-04\n",
            "Epoch 266/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.5753e-04 - mean_absolute_error: 5.5753e-04\n",
            "Epoch 267/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6.3634e-04 - mean_absolute_error: 6.3634e-04\n",
            "Epoch 268/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.1789e-04 - mean_absolute_error: 5.1789e-04\n",
            "Epoch 269/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.3998e-04 - mean_absolute_error: 5.3998e-04\n",
            "Epoch 270/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0011 - mean_absolute_error: 0.0011\n",
            "Epoch 271/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0018 - mean_absolute_error: 0.0018\n",
            "Epoch 272/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 7.3385e-04 - mean_absolute_error: 7.3385e-04\n",
            "Epoch 273/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.3759e-04 - mean_absolute_error: 5.3759e-04\n",
            "Epoch 274/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.4340e-04 - mean_absolute_error: 5.4340e-04\n",
            "Epoch 275/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.3231e-04 - mean_absolute_error: 5.3231e-04\n",
            "Epoch 276/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.5352e-04 - mean_absolute_error: 5.5352e-04\n",
            "Epoch 277/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.4202e-04 - mean_absolute_error: 5.4202e-04\n",
            "Epoch 278/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.6323e-04 - mean_absolute_error: 5.6323e-04\n",
            "Epoch 279/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6.5022e-04 - mean_absolute_error: 6.5022e-04\n",
            "Epoch 280/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 6.0858e-04 - mean_absolute_error: 6.0858e-04\n",
            "Epoch 281/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6.1330e-04 - mean_absolute_error: 6.1330e-04\n",
            "Epoch 282/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.7714e-04 - mean_absolute_error: 5.7714e-04\n",
            "Epoch 283/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 6.0018e-04 - mean_absolute_error: 6.0018e-04\n",
            "Epoch 284/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0026 - mean_absolute_error: 0.0026\n",
            "Epoch 285/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.9532e-04 - mean_absolute_error: 5.9532e-04\n",
            "Epoch 286/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 5.2282e-04 - mean_absolute_error: 5.2282e-04\n",
            "Epoch 287/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.6696e-04 - mean_absolute_error: 5.6696e-04\n",
            "Epoch 288/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.8951e-04 - mean_absolute_error: 5.8951e-04\n",
            "Epoch 289/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 5.8641e-04 - mean_absolute_error: 5.8641e-04\n",
            "Epoch 290/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.8852e-04 - mean_absolute_error: 5.8852e-04\n",
            "Epoch 291/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 9.1337e-04 - mean_absolute_error: 9.1337e-04\n",
            "Epoch 292/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6.0828e-04 - mean_absolute_error: 6.0828e-04\n",
            "Epoch 293/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 6.3597e-04 - mean_absolute_error: 6.3597e-04\n",
            "Epoch 294/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.3392e-04 - mean_absolute_error: 5.3392e-04\n",
            "Epoch 295/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 5.4594e-04 - mean_absolute_error: 5.4594e-04\n",
            "Epoch 296/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0045 - mean_absolute_error: 0.0045\n",
            "Epoch 297/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0016 - mean_absolute_error: 0.0016\n",
            "Epoch 298/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.8910e-04 - mean_absolute_error: 5.8910e-04\n",
            "Epoch 299/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 7.5987e-04 - mean_absolute_error: 7.5987e-04\n",
            "Epoch 300/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 5.5403e-04 - mean_absolute_error: 5.5403e-04\n",
            "Epoch 301/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.5055e-04 - mean_absolute_error: 5.5055e-04\n",
            "Epoch 302/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 5.5536e-04 - mean_absolute_error: 5.5536e-04\n",
            "Epoch 303/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 5.4612e-04 - mean_absolute_error: 5.4612e-04\n",
            "Epoch 304/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 6.0220e-04 - mean_absolute_error: 6.0220e-04\n",
            "Epoch 305/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.0015 - mean_absolute_error: 0.0015\n",
            "Epoch 306/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 5.2211e-04 - mean_absolute_error: 5.2211e-04\n",
            "Epoch 307/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 5.1414e-04 - mean_absolute_error: 5.1414e-04\n",
            "Epoch 308/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 5.1695e-04 - mean_absolute_error: 5.1695e-04\n",
            "Epoch 309/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 5.4722e-04 - mean_absolute_error: 5.4722e-04\n",
            "Epoch 310/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.3300e-04 - mean_absolute_error: 5.3300e-04\n",
            "Epoch 311/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 5.5339e-04 - mean_absolute_error: 5.5339e-04\n",
            "Epoch 312/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0015 - mean_absolute_error: 0.0015\n",
            "Epoch 313/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 6.0169e-04 - mean_absolute_error: 6.0169e-04\n",
            "Epoch 314/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.2422e-04 - mean_absolute_error: 5.2422e-04\n",
            "Epoch 315/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.4430e-04 - mean_absolute_error: 5.4430e-04\n",
            "Epoch 316/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.9278e-04 - mean_absolute_error: 5.9278e-04\n",
            "Epoch 317/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.5619e-04 - mean_absolute_error: 5.5619e-04\n",
            "Epoch 318/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.7763e-04 - mean_absolute_error: 5.7763e-04\n",
            "Epoch 319/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0010 - mean_absolute_error: 0.0010   \n",
            "Epoch 320/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.2769e-04 - mean_absolute_error: 5.2769e-04\n",
            "Epoch 321/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.2443e-04 - mean_absolute_error: 5.2443e-04\n",
            "Epoch 322/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.2256e-04 - mean_absolute_error: 5.2256e-04\n",
            "Epoch 323/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 5.1565e-04 - mean_absolute_error: 5.1565e-04\n",
            "Epoch 324/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.2218e-04 - mean_absolute_error: 5.2218e-04\n",
            "Epoch 325/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 5.2645e-04 - mean_absolute_error: 5.2645e-04\n",
            "Epoch 326/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 5.6362e-04 - mean_absolute_error: 5.6362e-04\n",
            "Epoch 327/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 5.5564e-04 - mean_absolute_error: 5.5564e-04\n",
            "Epoch 328/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 9.6827e-04 - mean_absolute_error: 9.6827e-04\n",
            "Epoch 329/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 5.5705e-04 - mean_absolute_error: 5.5705e-04\n",
            "Epoch 330/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 6.0841e-04 - mean_absolute_error: 6.0841e-04\n",
            "Epoch 331/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 5.9371e-04 - mean_absolute_error: 5.9371e-04\n",
            "Epoch 332/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 6.0822e-04 - mean_absolute_error: 6.0822e-04\n",
            "Epoch 333/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 6.0426e-04 - mean_absolute_error: 6.0426e-04\n",
            "Epoch 334/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 5.8702e-04 - mean_absolute_error: 5.8702e-04\n",
            "Epoch 335/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 5.8474e-04 - mean_absolute_error: 5.8474e-04\n",
            "Epoch 336/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 5.7599e-04 - mean_absolute_error: 5.7599e-04\n",
            "Epoch 337/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 5.5202e-04 - mean_absolute_error: 5.5202e-04\n",
            "Epoch 338/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 5.5652e-04 - mean_absolute_error: 5.5652e-04\n",
            "Epoch 339/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 5.7765e-04 - mean_absolute_error: 5.7765e-04\n",
            "Epoch 340/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.0013 - mean_absolute_error: 0.0013\n",
            "Epoch 341/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 6.0345e-04 - mean_absolute_error: 6.0345e-04\n",
            "Epoch 342/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 5.3661e-04 - mean_absolute_error: 5.3661e-04\n",
            "Epoch 343/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 5.2118e-04 - mean_absolute_error: 5.2118e-04\n",
            "Epoch 344/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 5.2422e-04 - mean_absolute_error: 5.2422e-04\n",
            "Epoch 345/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.4369e-04 - mean_absolute_error: 5.4369e-04\n",
            "Epoch 346/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 5.5886e-04 - mean_absolute_error: 5.5886e-04\n",
            "Epoch 347/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 5.6561e-04 - mean_absolute_error: 5.6561e-04\n",
            "Epoch 348/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 5.2210e-04 - mean_absolute_error: 5.2210e-04\n",
            "Epoch 349/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 8.1219e-04 - mean_absolute_error: 8.1219e-04\n",
            "Epoch 350/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 5.4684e-04 - mean_absolute_error: 5.4684e-04\n",
            "Epoch 351/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0017 - mean_absolute_error: 0.0017\n",
            "Epoch 352/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 5.4659e-04 - mean_absolute_error: 5.4659e-04\n",
            "Epoch 353/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 5.7492e-04 - mean_absolute_error: 5.7492e-04\n",
            "Epoch 354/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 5.5973e-04 - mean_absolute_error: 5.5973e-04\n",
            "Epoch 355/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 5.4310e-04 - mean_absolute_error: 5.4310e-04\n",
            "Epoch 356/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 5.5536e-04 - mean_absolute_error: 5.5536e-04\n",
            "Epoch 357/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 5.2800e-04 - mean_absolute_error: 5.2800e-04\n",
            "Epoch 358/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 6.7851e-04 - mean_absolute_error: 6.7851e-04\n",
            "Epoch 359/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.5743e-04 - mean_absolute_error: 5.5743e-04\n",
            "Epoch 360/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0017 - mean_absolute_error: 0.0017\n",
            "Epoch 361/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.5597e-04 - mean_absolute_error: 5.5597e-04\n",
            "Epoch 362/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.9717e-04 - mean_absolute_error: 5.9717e-04\n",
            "Epoch 363/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.7258e-04 - mean_absolute_error: 5.7258e-04\n",
            "Epoch 364/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0012 - mean_absolute_error: 0.0012\n",
            "Epoch 365/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.6249e-04 - mean_absolute_error: 5.6249e-04\n",
            "Epoch 366/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.4124e-04 - mean_absolute_error: 5.4124e-04\n",
            "Epoch 367/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.1531e-04 - mean_absolute_error: 5.1531e-04\n",
            "Epoch 368/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.3318e-04 - mean_absolute_error: 5.3318e-04\n",
            "Epoch 369/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.1611e-04 - mean_absolute_error: 5.1611e-04\n",
            "Epoch 370/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.2502e-04 - mean_absolute_error: 5.2502e-04\n",
            "Epoch 371/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 5.3089e-04 - mean_absolute_error: 5.3089e-04\n",
            "Epoch 372/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 5.3101e-04 - mean_absolute_error: 5.3101e-04\n",
            "Epoch 373/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 5.3620e-04 - mean_absolute_error: 5.3620e-04\n",
            "Epoch 374/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.2181e-04 - mean_absolute_error: 5.2181e-04\n",
            "Epoch 375/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.5349e-04 - mean_absolute_error: 5.5349e-04\n",
            "Epoch 376/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 5.4418e-04 - mean_absolute_error: 5.4418e-04\n",
            "Epoch 377/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 5.3876e-04 - mean_absolute_error: 5.3876e-04\n",
            "Epoch 378/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.0012 - mean_absolute_error: 0.0012   \n",
            "Epoch 379/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.4554e-04 - mean_absolute_error: 5.4554e-04\n",
            "Epoch 380/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.1585e-04 - mean_absolute_error: 5.1585e-04\n",
            "Epoch 381/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.7859e-04 - mean_absolute_error: 5.7859e-04\n",
            "Epoch 382/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.3908e-04 - mean_absolute_error: 5.3908e-04\n",
            "Epoch 383/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.2601e-04 - mean_absolute_error: 5.2601e-04\n",
            "Epoch 384/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.3883e-04 - mean_absolute_error: 5.3883e-04\n",
            "Epoch 385/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.7949e-04 - mean_absolute_error: 5.7949e-04\n",
            "Epoch 386/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.6547e-04 - mean_absolute_error: 5.6547e-04\n",
            "Epoch 387/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 5.5006e-04 - mean_absolute_error: 5.5006e-04\n",
            "Epoch 388/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0019 - mean_absolute_error: 0.0019\n",
            "Epoch 389/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 5.4454e-04 - mean_absolute_error: 5.4454e-04\n",
            "Epoch 390/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 5.2239e-04 - mean_absolute_error: 5.2239e-04\n",
            "Epoch 391/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 5.2131e-04 - mean_absolute_error: 5.2131e-04\n",
            "Epoch 392/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 5.2540e-04 - mean_absolute_error: 5.2540e-04\n",
            "Epoch 393/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 5.3950e-04 - mean_absolute_error: 5.3950e-04\n",
            "Epoch 394/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 6.1538e-04 - mean_absolute_error: 6.1538e-04\n",
            "Epoch 395/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 5.3744e-04 - mean_absolute_error: 5.3744e-04\n",
            "Epoch 396/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 6.9656e-04 - mean_absolute_error: 6.9656e-04\n",
            "Epoch 397/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 5.9672e-04 - mean_absolute_error: 5.9672e-04\n",
            "Epoch 398/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 6.0424e-04 - mean_absolute_error: 6.0424e-04\n",
            "Epoch 399/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 6.1056e-04 - mean_absolute_error: 6.1056e-04\n",
            "Epoch 400/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 5.7060e-04 - mean_absolute_error: 5.7060e-04\n",
            "Epoch 401/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 5.4358e-04 - mean_absolute_error: 5.4358e-04\n",
            "Epoch 402/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 5.9553e-04 - mean_absolute_error: 5.9553e-04\n",
            "Epoch 403/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 5.4905e-04 - mean_absolute_error: 5.4905e-04\n",
            "Epoch 404/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 5.3076e-04 - mean_absolute_error: 5.3076e-04\n",
            "Epoch 405/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 5.4582e-04 - mean_absolute_error: 5.4582e-04\n",
            "Epoch 406/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 5.4176e-04 - mean_absolute_error: 5.4176e-04\n",
            "Epoch 407/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.1925e-04 - mean_absolute_error: 5.1925e-04\n",
            "Epoch 408/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 5.2815e-04 - mean_absolute_error: 5.2815e-04\n",
            "Epoch 409/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 5.4028e-04 - mean_absolute_error: 5.4028e-04\n",
            "Epoch 410/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.1690e-04 - mean_absolute_error: 5.1690e-04\n",
            "Epoch 411/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 5.4247e-04 - mean_absolute_error: 5.4247e-04\n",
            "Epoch 412/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.3347e-04 - mean_absolute_error: 5.3347e-04\n",
            "Epoch 413/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.3159e-04 - mean_absolute_error: 5.3159e-04\n",
            "Epoch 414/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 5.4743e-04 - mean_absolute_error: 5.4743e-04\n",
            "Epoch 415/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.0013 - mean_absolute_error: 0.0013   \n",
            "Epoch 416/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 5.6752e-04 - mean_absolute_error: 5.6752e-04\n",
            "Epoch 417/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 5.6689e-04 - mean_absolute_error: 5.6689e-04\n",
            "Epoch 418/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 5.4227e-04 - mean_absolute_error: 5.4227e-04\n",
            "Epoch 419/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 5.8488e-04 - mean_absolute_error: 5.8488e-04\n",
            "Epoch 420/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.8592e-04 - mean_absolute_error: 5.8592e-04\n",
            "Epoch 421/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.4326e-04 - mean_absolute_error: 5.4326e-04\n",
            "Epoch 422/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.6157e-04 - mean_absolute_error: 5.6157e-04\n",
            "Epoch 423/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 5.5526e-04 - mean_absolute_error: 5.5526e-04\n",
            "Epoch 424/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 5.5771e-04 - mean_absolute_error: 5.5771e-04\n",
            "Epoch 425/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.2909e-04 - mean_absolute_error: 5.2909e-04\n",
            "Epoch 426/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.2835e-04 - mean_absolute_error: 5.2835e-04\n",
            "Epoch 427/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.4184e-04 - mean_absolute_error: 5.4184e-04\n",
            "Epoch 428/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.5746e-04 - mean_absolute_error: 5.5746e-04\n",
            "Epoch 429/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.3795e-04 - mean_absolute_error: 5.3795e-04\n",
            "Epoch 430/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.3256e-04 - mean_absolute_error: 5.3256e-04\n",
            "Epoch 431/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.3060e-04 - mean_absolute_error: 5.3060e-04\n",
            "Epoch 432/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 9.6481e-04 - mean_absolute_error: 9.6481e-04\n",
            "Epoch 433/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.3601e-04 - mean_absolute_error: 5.3601e-04\n",
            "Epoch 434/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 5.1948e-04 - mean_absolute_error: 5.1948e-04\n",
            "Epoch 435/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 5.2227e-04 - mean_absolute_error: 5.2227e-04\n",
            "Epoch 436/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 5.3600e-04 - mean_absolute_error: 5.3600e-04\n",
            "Epoch 437/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 5.7989e-04 - mean_absolute_error: 5.7989e-04\n",
            "Epoch 438/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 8.5345e-04 - mean_absolute_error: 8.5345e-04\n",
            "Epoch 439/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.0023 - mean_absolute_error: 0.0023\n",
            "Epoch 440/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 5.4997e-04 - mean_absolute_error: 5.4997e-04\n",
            "Epoch 441/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 6.2569e-04 - mean_absolute_error: 6.2569e-04\n",
            "Epoch 442/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.5413e-04 - mean_absolute_error: 5.5413e-04\n",
            "Epoch 443/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 6.6374e-04 - mean_absolute_error: 6.6374e-04\n",
            "Epoch 444/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 7.7834e-04 - mean_absolute_error: 7.7834e-04\n",
            "Epoch 445/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 5.7950e-04 - mean_absolute_error: 5.7950e-04\n",
            "Epoch 446/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.3117e-04 - mean_absolute_error: 5.3117e-04\n",
            "Epoch 447/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 5.5283e-04 - mean_absolute_error: 5.5283e-04\n",
            "Epoch 448/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 5.7519e-04 - mean_absolute_error: 5.7519e-04\n",
            "Epoch 449/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 5.6902e-04 - mean_absolute_error: 5.6902e-04\n",
            "Epoch 450/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 5.3053e-04 - mean_absolute_error: 5.3053e-04\n",
            "Epoch 451/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 5.7377e-04 - mean_absolute_error: 5.7377e-04\n",
            "Epoch 452/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 5.7042e-04 - mean_absolute_error: 5.7042e-04\n",
            "Epoch 453/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 5.5623e-04 - mean_absolute_error: 5.5623e-04\n",
            "Epoch 454/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 5.3805e-04 - mean_absolute_error: 5.3805e-04\n",
            "Epoch 455/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 5.5060e-04 - mean_absolute_error: 5.5060e-04\n",
            "Epoch 456/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 5.5795e-04 - mean_absolute_error: 5.5795e-04\n",
            "Epoch 457/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 5.6306e-04 - mean_absolute_error: 5.6306e-04\n",
            "Epoch 458/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 5.5575e-04 - mean_absolute_error: 5.5575e-04\n",
            "Epoch 459/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 5.9461e-04 - mean_absolute_error: 5.9461e-04\n",
            "Epoch 460/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 6.0827e-04 - mean_absolute_error: 6.0827e-04\n",
            "Epoch 461/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 5.6549e-04 - mean_absolute_error: 5.6549e-04\n",
            "Epoch 462/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 5.5878e-04 - mean_absolute_error: 5.5878e-04\n",
            "Epoch 463/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 5.3064e-04 - mean_absolute_error: 5.3064e-04\n",
            "Epoch 464/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 5.8147e-04 - mean_absolute_error: 5.8147e-04\n",
            "Epoch 465/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 5.9447e-04 - mean_absolute_error: 5.9447e-04\n",
            "Epoch 466/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 5.2917e-04 - mean_absolute_error: 5.2917e-04\n",
            "Epoch 467/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 5.3649e-04 - mean_absolute_error: 5.3649e-04\n",
            "Epoch 468/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 5.6020e-04 - mean_absolute_error: 5.6020e-04\n",
            "Epoch 469/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 5.2988e-04 - mean_absolute_error: 5.2988e-04\n",
            "Epoch 470/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 5.4338e-04 - mean_absolute_error: 5.4338e-04\n",
            "Epoch 471/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 5.4007e-04 - mean_absolute_error: 5.4007e-04\n",
            "Epoch 472/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 5.8684e-04 - mean_absolute_error: 5.8684e-04\n",
            "Epoch 473/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 5.6115e-04 - mean_absolute_error: 5.6115e-04\n",
            "Epoch 474/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.7439e-04 - mean_absolute_error: 5.7439e-04\n",
            "Epoch 475/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 5.5668e-04 - mean_absolute_error: 5.5668e-04\n",
            "Epoch 476/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 5.4161e-04 - mean_absolute_error: 5.4161e-04\n",
            "Epoch 477/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 5.3602e-04 - mean_absolute_error: 5.3602e-04\n",
            "Epoch 478/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.4146e-04 - mean_absolute_error: 5.4146e-04\n",
            "Epoch 479/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 5.3722e-04 - mean_absolute_error: 5.3722e-04\n",
            "Epoch 480/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 5.3218e-04 - mean_absolute_error: 5.3218e-04\n",
            "Epoch 481/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 5.2442e-04 - mean_absolute_error: 5.2442e-04\n",
            "Epoch 482/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 5.7971e-04 - mean_absolute_error: 5.7971e-04\n",
            "Epoch 483/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.6082e-04 - mean_absolute_error: 5.6082e-04\n",
            "Epoch 484/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 5.7682e-04 - mean_absolute_error: 5.7682e-04\n",
            "Epoch 485/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 5.8282e-04 - mean_absolute_error: 5.8282e-04\n",
            "Epoch 486/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.7369e-04 - mean_absolute_error: 5.7369e-04\n",
            "Epoch 487/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.4603e-04 - mean_absolute_error: 5.4603e-04\n",
            "Epoch 488/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.5540e-04 - mean_absolute_error: 5.5540e-04\n",
            "Epoch 489/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.9185e-04 - mean_absolute_error: 5.9185e-04\n",
            "Epoch 490/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.5724e-04 - mean_absolute_error: 5.5724e-04\n",
            "Epoch 491/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 5.3436e-04 - mean_absolute_error: 5.3436e-04\n",
            "Epoch 492/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 5.1906e-04 - mean_absolute_error: 5.1906e-04\n",
            "Epoch 493/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0013 - mean_absolute_error: 0.0013\n",
            "Epoch 494/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.4455e-04 - mean_absolute_error: 5.4455e-04\n",
            "Epoch 495/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.5483e-04 - mean_absolute_error: 5.5483e-04\n",
            "Epoch 496/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 9.9656e-04 - mean_absolute_error: 9.9656e-04\n",
            "Epoch 497/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.7203e-04 - mean_absolute_error: 5.7203e-04\n",
            "Epoch 498/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.7399e-04 - mean_absolute_error: 5.7399e-04\n",
            "Epoch 499/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.5315e-04 - mean_absolute_error: 5.5315e-04\n",
            "Epoch 500/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 5.4811e-04 - mean_absolute_error: 5.4811e-04\n"
          ]
        }
      ],
      "source": [
        "# callbacks = [EarlyStopping(patience=8, monitor='val_loss',mode='min',verbose=1),CSVLogger(filename='east.csv')]\n",
        "history = model.fit(x,y, epochs=500, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "qAHZA8wK9S9s",
        "outputId": "8e1608af-a3b0-4c43-c025-87a3eb0c47e9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'val_loss'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-afff23f49c13>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_loss'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPjuGpti9XfI"
      },
      "outputs": [],
      "source": [
        "# accuracy\n",
        "plt.plot(history.history['mean_absolute_error'])\n",
        "plt.plot(history.history['val_mean_absolute_error'])\n",
        "plt.title('MAE vs Epoch')\n",
        "plt.ylabel('MAE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtq7LQmq9YB_"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxRXPnuh9av-"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaqNO0aI9dqD"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uL_9A_rR9dsn"
      },
      "outputs": [],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pOmZu_A9duq",
        "outputId": "a8b92fe7-7e0d-43df-c459-0850047cf43f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step\n",
            "Mean Squared Error: 2.1075945565619887e-06\n",
            "Root Mean Squared Error: 0.0014517556807403884\n",
            "Mean Absolute Error: 0.0005986520428611572\n",
            "R-squared: -11.527386914490927\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Get predicted values from the model\n",
        "predicted_values = model.predict(x)\n",
        "\n",
        "# True labels\n",
        "true_values = y\n",
        "\n",
        "# Calculate regression metrics\n",
        "mse = mean_squared_error(true_values, predicted_values)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(true_values, predicted_values)\n",
        "r2 = r2_score(true_values, predicted_values)\n",
        "\n",
        "print('Mean Squared Error:', mse)\n",
        "print('Root Mean Squared Error:', rmse)\n",
        "print('Mean Absolute Error:', mae)\n",
        "print('R-squared:', r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0EAe_hk-PXw",
        "outputId": "01243572-0f28-4905-f2e3-253adb15b83a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 406ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00021558, 0.00039796]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "model.predict([[0.02\t,7]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt7MvrSAPNEx",
        "outputId": "c31269c2-2de6-4103-af92-1e69df887f63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bayesian-optimization\n",
            "  Downloading bayesian_optimization-1.4.3-py3-none-any.whl (18 kB)\n",
            "Collecting pyswarm\n",
            "  Downloading pyswarm-0.6.tar.gz (4.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting deap\n",
            "  Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nevergrad\n",
            "  Downloading nevergrad-1.0.3-py3-none-any.whl (490 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m490.9/490.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.2.2)\n",
            "Collecting colorama>=0.4.6 (from bayesian-optimization)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting cma>=2.6.0 (from nevergrad)\n",
            "  Downloading cma-3.3.0-py3-none-any.whl (260 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m260.7/260.7 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from nevergrad) (4.12.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nevergrad) (2.0.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->nevergrad) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nevergrad) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nevergrad) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->nevergrad) (1.16.0)\n",
            "Building wheels for collected packages: pyswarm\n",
            "  Building wheel for pyswarm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyswarm: filename=pyswarm-0.6-py3-none-any.whl size=4464 sha256=8a9c61c21e68aabf749980a7a1ce1e9e280c04d560ef61414edb73bc1b2dafa9\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/67/40/62fa158f497f942277cbab8199b05cb61c571ab324e67ad0d6\n",
            "Successfully built pyswarm\n",
            "Installing collected packages: pyswarm, deap, colorama, cma, bayesian-optimization, nevergrad\n",
            "Successfully installed bayesian-optimization-1.4.3 cma-3.3.0 colorama-0.4.6 deap-1.4.1 nevergrad-1.0.3 pyswarm-0.6\n"
          ]
        }
      ],
      "source": [
        "#INVERSE DESIGN\n",
        "!pip install bayesian-optimization pyswarm deap nevergrad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2K8-0RRuFOQ5",
        "outputId": "0082461c-6b55-4a4a-869c-23e2f56fc447"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          ron_rv   roff_rv\n",
              "0   8.804207e-09  0.000007\n",
              "1   3.050072e-08  0.005373\n",
              "2   3.682850e-08  0.000663\n",
              "3   5.926848e-06  0.000256\n",
              "4   2.387368e-05  0.000407\n",
              "5   1.113548e-04  0.000647\n",
              "6   8.804207e-09  0.000007\n",
              "7   3.050072e-08  0.005373\n",
              "8   3.682850e-08  0.000663\n",
              "9   5.926848e-06  0.000256\n",
              "10  2.387368e-05  0.000407\n",
              "11  1.113548e-04  0.000647\n",
              "12  8.804207e-09  0.000007\n",
              "13  3.050072e-08  0.005373\n",
              "14  3.682850e-08  0.000663\n",
              "15  5.926848e-06  0.000256\n",
              "16  2.387368e-05  0.000407\n",
              "17  1.113548e-04  0.000647\n",
              "18  8.804207e-09  0.000007\n",
              "19  3.050072e-08  0.005373\n",
              "20  3.682850e-08  0.000663\n",
              "21  5.926848e-06  0.000256\n",
              "22  2.387368e-05  0.000407\n",
              "23  1.113548e-04  0.000647\n",
              "24  8.804207e-09  0.000007\n",
              "25  3.050072e-08  0.005373\n",
              "26  3.682850e-08  0.000663\n",
              "27  5.926848e-06  0.000256\n",
              "28  2.387368e-05  0.000407\n",
              "29  1.113548e-04  0.000647\n",
              "30  8.804207e-09  0.000007\n",
              "31  3.050072e-08  0.005373\n",
              "32  3.682850e-08  0.000663\n",
              "33  5.926848e-06  0.000256\n",
              "34  2.387368e-05  0.000407\n",
              "35  1.113548e-04  0.000647\n",
              "36  8.804207e-09  0.000007\n",
              "37  3.050072e-08  0.005373\n",
              "38  3.682850e-08  0.000663\n",
              "39  5.926848e-06  0.000256\n",
              "40  2.387368e-05  0.000407\n",
              "41  1.113548e-04  0.000647\n",
              "42  8.804207e-09  0.000007\n",
              "43  3.050072e-08  0.005373\n",
              "44  3.682850e-08  0.000663\n",
              "45  5.926848e-06  0.000256\n",
              "46  2.387368e-05  0.000407\n",
              "47  1.113548e-04  0.000647"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2fa06f4-3238-42db-93be-44cd49e2419a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ron_rv</th>\n",
              "      <th>roff_rv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.804207e-09</td>\n",
              "      <td>0.000007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.050072e-08</td>\n",
              "      <td>0.005373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.682850e-08</td>\n",
              "      <td>0.000663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.926848e-06</td>\n",
              "      <td>0.000256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.387368e-05</td>\n",
              "      <td>0.000407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.113548e-04</td>\n",
              "      <td>0.000647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>8.804207e-09</td>\n",
              "      <td>0.000007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3.050072e-08</td>\n",
              "      <td>0.005373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3.682850e-08</td>\n",
              "      <td>0.000663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5.926848e-06</td>\n",
              "      <td>0.000256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2.387368e-05</td>\n",
              "      <td>0.000407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.113548e-04</td>\n",
              "      <td>0.000647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>8.804207e-09</td>\n",
              "      <td>0.000007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3.050072e-08</td>\n",
              "      <td>0.005373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>3.682850e-08</td>\n",
              "      <td>0.000663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>5.926848e-06</td>\n",
              "      <td>0.000256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2.387368e-05</td>\n",
              "      <td>0.000407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.113548e-04</td>\n",
              "      <td>0.000647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>8.804207e-09</td>\n",
              "      <td>0.000007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3.050072e-08</td>\n",
              "      <td>0.005373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>3.682850e-08</td>\n",
              "      <td>0.000663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>5.926848e-06</td>\n",
              "      <td>0.000256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2.387368e-05</td>\n",
              "      <td>0.000407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1.113548e-04</td>\n",
              "      <td>0.000647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>8.804207e-09</td>\n",
              "      <td>0.000007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>3.050072e-08</td>\n",
              "      <td>0.005373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>3.682850e-08</td>\n",
              "      <td>0.000663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>5.926848e-06</td>\n",
              "      <td>0.000256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2.387368e-05</td>\n",
              "      <td>0.000407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1.113548e-04</td>\n",
              "      <td>0.000647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>8.804207e-09</td>\n",
              "      <td>0.000007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>3.050072e-08</td>\n",
              "      <td>0.005373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>3.682850e-08</td>\n",
              "      <td>0.000663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>5.926848e-06</td>\n",
              "      <td>0.000256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>2.387368e-05</td>\n",
              "      <td>0.000407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>1.113548e-04</td>\n",
              "      <td>0.000647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>8.804207e-09</td>\n",
              "      <td>0.000007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>3.050072e-08</td>\n",
              "      <td>0.005373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>3.682850e-08</td>\n",
              "      <td>0.000663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>5.926848e-06</td>\n",
              "      <td>0.000256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>2.387368e-05</td>\n",
              "      <td>0.000407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>1.113548e-04</td>\n",
              "      <td>0.000647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>8.804207e-09</td>\n",
              "      <td>0.000007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>3.050072e-08</td>\n",
              "      <td>0.005373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>3.682850e-08</td>\n",
              "      <td>0.000663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>5.926848e-06</td>\n",
              "      <td>0.000256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>2.387368e-05</td>\n",
              "      <td>0.000407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>1.113548e-04</td>\n",
              "      <td>0.000647</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2fa06f4-3238-42db-93be-44cd49e2419a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e2fa06f4-3238-42db-93be-44cd49e2419a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e2fa06f4-3238-42db-93be-44cd49e2419a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d1b972d1-153b-42ac-8ba6-8f8a51464cab\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d1b972d1-153b-42ac-8ba6-8f8a51464cab')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d1b972d1-153b-42ac-8ba6-8f8a51464cab button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_edcf572b-1c1d-452e-845c-474d0bcdd469\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('y')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_edcf572b-1c1d-452e-845c-474d0bcdd469 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('y');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "y",
              "summary": "{\n  \"name\": \"y\",\n  \"rows\": 48,\n  \"fields\": [\n    {\n      \"column\": \"ron_rv\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.059262021110898e-05,\n        \"min\": 8.80420741713041e-09,\n        \"max\": 0.000111354848017854,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          8.80420741713041e-09,\n          3.05007199370124e-08,\n          0.000111354848017854\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roff_rv\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0018884189079215927,\n        \"min\": 7.18116144058856e-06,\n        \"max\": 0.00537337589369173,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          7.18116144058856e-06,\n          0.00537337589369173,\n          0.00064720272876936\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qAKWofsBKSWT",
        "outputId": "ad62ce08-0db4-496b-a59c-61ff852bb3de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    defect_density  no_of_defects\n",
              "0         0.023444              1\n",
              "1         0.023553              2\n",
              "2         0.023662              3\n",
              "3         0.023770              4\n",
              "4         0.023879              5\n",
              "5         0.023987              6\n",
              "6         0.024096              7\n",
              "7         0.024204              8\n",
              "8         0.024313              9\n",
              "9         0.024421             10\n",
              "10        0.024530             11\n",
              "11        0.024638             12\n",
              "12        0.024747             13\n",
              "13        0.024855             14\n",
              "14        0.024964             15\n",
              "15        0.025073             16\n",
              "16        0.025181             17\n",
              "17        0.025290             18\n",
              "18        0.025398             19\n",
              "19        0.025507             20\n",
              "20        0.025615             21\n",
              "21        0.025724             22\n",
              "22        0.025832             23\n",
              "23        0.025941             24\n",
              "24        0.028654             25\n",
              "25        0.028763             26\n",
              "26        0.028871             27\n",
              "27        0.028980             28\n",
              "28        0.029088             29\n",
              "29        0.029197             30\n",
              "30        0.029306             31\n",
              "31        0.029414             32\n",
              "32        0.029523             33\n",
              "33        0.029631             34\n",
              "34        0.029740             35\n",
              "35        0.029848             36\n",
              "36        0.029957             37\n",
              "37        0.030065             38\n",
              "38        0.030174             39\n",
              "39        0.030282             40\n",
              "40        0.030391             41\n",
              "41        0.030499             42\n",
              "42        0.030608             43\n",
              "43        0.030717             44\n",
              "44        0.030825             45\n",
              "45        0.030934             46\n",
              "46        0.031042             47\n",
              "47        0.031151             48"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65fbd9a9-8f3e-4e83-aca7-b0743eb71ed6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>defect_density</th>\n",
              "      <th>no_of_defects</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.023444</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.023553</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.023662</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.023770</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.023879</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.023987</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.024096</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.024204</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.024313</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.024421</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.024530</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.024638</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.024747</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.024855</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.024964</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.025073</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.025181</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.025290</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.025398</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.025507</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.025615</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.025724</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.025832</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.025941</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.028654</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.028763</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.028871</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.028980</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.029088</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.029197</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.029306</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.029414</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.029523</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.029631</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.029740</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.029848</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.029957</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.030065</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.030174</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.030282</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.030391</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.030499</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.030608</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.030717</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.030825</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.030934</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.031042</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.031151</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65fbd9a9-8f3e-4e83-aca7-b0743eb71ed6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-65fbd9a9-8f3e-4e83-aca7-b0743eb71ed6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-65fbd9a9-8f3e-4e83-aca7-b0743eb71ed6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a4afe5b4-6853-405f-9231-c96d0c328bc9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a4afe5b4-6853-405f-9231-c96d0c328bc9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a4afe5b4-6853-405f-9231-c96d0c328bc9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d4c0e481-3889-48f7-b5cf-d2b9fcb173ef\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('x')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d4c0e481-3889-48f7-b5cf-d2b9fcb173ef button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('x');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x",
              "summary": "{\n  \"name\": \"x\",\n  \"rows\": 48,\n  \"fields\": [\n    {\n      \"column\": \"defect_density\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0027398128352373397,\n        \"min\": 0.023444429216893,\n        \"max\": 0.0311506999317051,\n        \"num_unique_values\": 48,\n        \"samples\": [\n          0.0289799194486594,\n          0.0303909267626391,\n          0.0288713804245072\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"no_of_defects\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 1,\n        \"max\": 48,\n        \"num_unique_values\": 48,\n        \"samples\": [\n          28,\n          41,\n          27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsgJUdKmL5OJ"
      },
      "outputs": [],
      "source": [
        "# Au = 1, W = 2, Mo = 3, Sn = 4, Pt = 5, Ti = 6,\n",
        "# H-BN = 11, MoS2 = 12, MoSe2 = 13,PdSe2 = 14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7AeL8tyAY0h"
      },
      "outputs": [],
      "source": [
        "# from scipy.optimize import minimize\n",
        "# # Desired target output\n",
        "# target_output = np.array([0.000256, 5.926848e-06, 0.877, -1.50])\n",
        "\n",
        "# # Define the loss function for optimization\n",
        "# def loss_function(x):\n",
        "#     x = np.array(x).reshape(1, -1)\n",
        "#     predicted_output = model.predict(x)\n",
        "#     loss = np.mean(np.abs(predicted_output - target_output))\n",
        "#     return loss\n",
        "\n",
        "# # Initial guess for the input parameters (can be random or based on domain knowledge)\n",
        "# # initial_guess = np.array([14, 3, 1, 6, 1, 0])\n",
        "# def generate_random_initial_guess(bounds):\n",
        "#     return [np.random.uniform(low, high) for low, high in bounds]\n",
        "\n",
        "# # Bounds for the input parameters (if applicable)\n",
        "# bounds = [(11, 14), (1, 6), (0.053, 100.000), (1, 6), (1, 6), (0, 6)]\n",
        "\n",
        "\n",
        "# initial_guess = generate_random_initial_guess(bounds)\n",
        "\n",
        "# # Perform the optimization\n",
        "# result = minimize(loss_function, initial_guess, bounds=bounds, method='L-BFGS-B')\n",
        "\n",
        "# # Optimized input parameters\n",
        "# optimized_input = result.x\n",
        "\n",
        "# print(\"Optimized Input Parameters:\")\n",
        "# print(optimized_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2p8Y2b65Z6Ir",
        "outputId": "7a785f77-6abf-41f3-db73-715771d19b6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Differential Evolution took 426.18 seconds\n",
            "Stopping search: Swarm best objective change less than 1e-08\n",
            "Particle Swarm Optimization took 24.77 seconds\n",
            "Simulated Annealing took 53.45 seconds\n",
            "Shgo took 683.90 seconds\n",
            "Grid Search took 703.62 seconds\n",
            "|   iter    |  target   |  param1   |  param2   |  param3   |  param4   |  param5   |  param6   |\n",
            "-------------------------------------------------------------------------------------------------\n",
            "| \u001b[0m1        \u001b[0m | \u001b[0m-0.1473  \u001b[0m | \u001b[0m12.12    \u001b[0m | \u001b[0m5.754    \u001b[0m | \u001b[0m73.21    \u001b[0m | \u001b[0m3.993    \u001b[0m | \u001b[0m1.78     \u001b[0m | \u001b[0m0.936    \u001b[0m |\n",
            "| \u001b[95m2        \u001b[0m | \u001b[95m-0.1264  \u001b[0m | \u001b[95m11.17    \u001b[0m | \u001b[95m5.331    \u001b[0m | \u001b[95m60.13    \u001b[0m | \u001b[95m4.54     \u001b[0m | \u001b[95m1.103    \u001b[0m | \u001b[95m5.819    \u001b[0m |\n",
            "| \u001b[0m3        \u001b[0m | \u001b[0m-0.129   \u001b[0m | \u001b[0m13.5     \u001b[0m | \u001b[0m2.062    \u001b[0m | \u001b[0m18.23    \u001b[0m | \u001b[0m1.917    \u001b[0m | \u001b[0m2.521    \u001b[0m | \u001b[0m3.149    \u001b[0m |\n",
            "| \u001b[95m4        \u001b[0m | \u001b[95m-0.1212  \u001b[0m | \u001b[95m12.3     \u001b[0m | \u001b[95m2.456    \u001b[0m | \u001b[95m61.21    \u001b[0m | \u001b[95m1.697    \u001b[0m | \u001b[95m2.461    \u001b[0m | \u001b[95m2.198    \u001b[0m |\n",
            "| \u001b[0m5        \u001b[0m | \u001b[0m-0.1315  \u001b[0m | \u001b[0m12.37    \u001b[0m | \u001b[0m4.926    \u001b[0m | \u001b[0m20.01    \u001b[0m | \u001b[0m3.571    \u001b[0m | \u001b[0m3.962    \u001b[0m | \u001b[0m0.2787   \u001b[0m |\n",
            "| \u001b[0m6        \u001b[0m | \u001b[0m-0.1332  \u001b[0m | \u001b[0m13.16    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m54.92    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m3.289    \u001b[0m | \u001b[0m1.355    \u001b[0m |\n",
            "| \u001b[0m7        \u001b[0m | \u001b[0m-0.127   \u001b[0m | \u001b[0m11.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m62.55    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m3.519    \u001b[0m | \u001b[0m5.943    \u001b[0m |\n",
            "| \u001b[95m8        \u001b[0m | \u001b[95m-0.1171  \u001b[0m | \u001b[95m11.0     \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m61.6     \u001b[0m | \u001b[95m5.522    \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.558    \u001b[0m |\n",
            "| \u001b[0m9        \u001b[0m | \u001b[0m-0.1171  \u001b[0m | \u001b[0m11.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m61.87    \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
            "| \u001b[0m10       \u001b[0m | \u001b[0m-0.1195  \u001b[0m | \u001b[0m13.15    \u001b[0m | \u001b[0m5.718    \u001b[0m | \u001b[0m59.79    \u001b[0m | \u001b[0m5.454    \u001b[0m | \u001b[0m4.81     \u001b[0m | \u001b[0m0.04723  \u001b[0m |\n",
            "| \u001b[0m11       \u001b[0m | \u001b[0m-0.1251  \u001b[0m | \u001b[0m11.0     \u001b[0m | \u001b[0m1.297    \u001b[0m | \u001b[0m0.053    \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m6.0      \u001b[0m |\n",
            "| \u001b[0m12       \u001b[0m | \u001b[0m-0.2355  \u001b[0m | \u001b[0m14.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m100.0    \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m0.4034   \u001b[0m |\n",
            "| \u001b[0m13       \u001b[0m | \u001b[0m-0.1323  \u001b[0m | \u001b[0m14.0     \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m0.053    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
            "| \u001b[0m14       \u001b[0m | \u001b[0m-0.1399  \u001b[0m | \u001b[0m14.0     \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m10.21    \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m6.0      \u001b[0m |\n",
            "| \u001b[0m15       \u001b[0m | \u001b[0m-0.1327  \u001b[0m | \u001b[0m11.21    \u001b[0m | \u001b[0m1.116    \u001b[0m | \u001b[0m30.87    \u001b[0m | \u001b[0m5.321    \u001b[0m | \u001b[0m3.777    \u001b[0m | \u001b[0m5.906    \u001b[0m |\n",
            "| \u001b[95m16       \u001b[0m | \u001b[95m-0.1065  \u001b[0m | \u001b[95m11.0     \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m8.146    \u001b[0m | \u001b[95m6.0      \u001b[0m | \u001b[95m6.0      \u001b[0m | \u001b[95m0.0      \u001b[0m |\n",
            "| \u001b[0m17       \u001b[0m | \u001b[0m-0.1414  \u001b[0m | \u001b[0m11.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m8.086    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m6.0      \u001b[0m |\n",
            "| \u001b[0m18       \u001b[0m | \u001b[0m-0.1216  \u001b[0m | \u001b[0m11.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m5.861    \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
            "| \u001b[0m19       \u001b[0m | \u001b[0m-0.1215  \u001b[0m | \u001b[0m14.0     \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m40.69    \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
            "| \u001b[0m20       \u001b[0m | \u001b[0m-0.113   \u001b[0m | \u001b[0m14.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m13.57    \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
            "| \u001b[0m21       \u001b[0m | \u001b[0m-0.1302  \u001b[0m | \u001b[0m14.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.053    \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
            "| \u001b[0m22       \u001b[0m | \u001b[0m-0.1254  \u001b[0m | \u001b[0m14.0     \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m40.83    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m6.0      \u001b[0m |\n",
            "| \u001b[0m23       \u001b[0m | \u001b[0m-0.1181  \u001b[0m | \u001b[0m14.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m34.59    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
            "| \u001b[0m24       \u001b[0m | \u001b[0m-0.1316  \u001b[0m | \u001b[0m11.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m41.09    \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
            "| \u001b[0m25       \u001b[0m | \u001b[0m-0.1089  \u001b[0m | \u001b[0m11.0     \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m8.559    \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
            "| \u001b[0m26       \u001b[0m | \u001b[0m-0.1333  \u001b[0m | \u001b[0m11.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m13.22    \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
            "| \u001b[0m27       \u001b[0m | \u001b[0m-0.1232  \u001b[0m | \u001b[0m14.0     \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m30.88    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
            "| \u001b[0m28       \u001b[0m | \u001b[0m-0.116   \u001b[0m | \u001b[0m12.61    \u001b[0m | \u001b[0m5.948    \u001b[0m | \u001b[0m66.38    \u001b[0m | \u001b[0m1.018    \u001b[0m | \u001b[0m3.501    \u001b[0m | \u001b[0m1.771    \u001b[0m |\n",
            "| \u001b[0m29       \u001b[0m | \u001b[0m-0.135   \u001b[0m | \u001b[0m11.2     \u001b[0m | \u001b[0m2.591    \u001b[0m | \u001b[0m43.33    \u001b[0m | \u001b[0m5.993    \u001b[0m | \u001b[0m1.322    \u001b[0m | \u001b[0m4.177    \u001b[0m |\n",
            "| \u001b[0m30       \u001b[0m | \u001b[0m-0.1337  \u001b[0m | \u001b[0m12.6     \u001b[0m | \u001b[0m3.365    \u001b[0m | \u001b[0m2.156    \u001b[0m | \u001b[0m3.893    \u001b[0m | \u001b[0m4.148    \u001b[0m | \u001b[0m3.792    \u001b[0m |\n",
            "| \u001b[0m31       \u001b[0m | \u001b[0m-0.1178  \u001b[0m | \u001b[0m14.0     \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m10.47    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
            "| \u001b[0m32       \u001b[0m | \u001b[0m-0.214   \u001b[0m | \u001b[0m13.47    \u001b[0m | \u001b[0m1.339    \u001b[0m | \u001b[0m95.73    \u001b[0m | \u001b[0m2.699    \u001b[0m | \u001b[0m1.24     \u001b[0m | \u001b[0m4.134    \u001b[0m |\n",
            "| \u001b[0m33       \u001b[0m | \u001b[0m-0.1206  \u001b[0m | \u001b[0m14.0     \u001b[0m | \u001b[0m2.825    \u001b[0m | \u001b[0m7.699    \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
            "| \u001b[0m34       \u001b[0m | \u001b[0m-0.1183  \u001b[0m | \u001b[0m14.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m67.64    \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m6.0      \u001b[0m |\n",
            "| \u001b[0m35       \u001b[0m | \u001b[0m-0.1209  \u001b[0m | \u001b[0m14.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m67.48    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
            "| \u001b[0m36       \u001b[0m | \u001b[0m-0.1363  \u001b[0m | \u001b[0m14.0     \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m30.28    \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
            "| \u001b[0m37       \u001b[0m | \u001b[0m-0.1294  \u001b[0m | \u001b[0m14.0     \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m34.29    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m6.0      \u001b[0m |\n",
            "| \u001b[0m38       \u001b[0m | \u001b[0m-0.1339  \u001b[0m | \u001b[0m11.0     \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m45.98    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
            "| \u001b[0m39       \u001b[0m | \u001b[0m-0.1225  \u001b[0m | \u001b[0m14.0     \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m64.21    \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m6.0      \u001b[0m |\n",
            "| \u001b[0m40       \u001b[0m | \u001b[0m-0.1205  \u001b[0m | \u001b[0m14.0     \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m64.74    \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
            "| \u001b[0m41       \u001b[0m | \u001b[0m-0.1242  \u001b[0m | \u001b[0m14.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m24.96    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
            "| \u001b[0m42       \u001b[0m | \u001b[0m-0.1401  \u001b[0m | \u001b[0m14.0     \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m20.86    \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m6.0      \u001b[0m |\n",
            "| \u001b[0m43       \u001b[0m | \u001b[0m-0.1182  \u001b[0m | \u001b[0m14.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m68.97    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m6.0      \u001b[0m |\n",
            "| \u001b[0m44       \u001b[0m | \u001b[0m-0.1369  \u001b[0m | \u001b[0m14.0     \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m50.86    \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m6.0      \u001b[0m |\n",
            "| \u001b[0m45       \u001b[0m | \u001b[0m-0.1244  \u001b[0m | \u001b[0m11.0     \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m3.045    \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
            "| \u001b[0m46       \u001b[0m | \u001b[0m-0.1243  \u001b[0m | \u001b[0m11.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m72.96    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m6.0      \u001b[0m |\n",
            "| \u001b[0m47       \u001b[0m | \u001b[0m-0.1225  \u001b[0m | \u001b[0m14.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m36.99    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
            "| \u001b[0m48       \u001b[0m | \u001b[0m-0.1314  \u001b[0m | \u001b[0m11.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m5.197    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
            "| \u001b[0m49       \u001b[0m | \u001b[0m-0.1211  \u001b[0m | \u001b[0m14.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m13.77    \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
            "| \u001b[0m50       \u001b[0m | \u001b[0m-0.116   \u001b[0m | \u001b[0m11.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m67.61    \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m6.0      \u001b[0m |\n",
            "| \u001b[0m51       \u001b[0m | \u001b[0m-0.1225  \u001b[0m | \u001b[0m14.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m62.95    \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m6.0      \u001b[0m |\n",
            "| \u001b[0m52       \u001b[0m | \u001b[0m-0.1177  \u001b[0m | \u001b[0m14.0     \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m61.49    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
            "| \u001b[0m53       \u001b[0m | \u001b[0m-0.1195  \u001b[0m | \u001b[0m11.0     \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m67.84    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m6.0      \u001b[0m |\n",
            "| \u001b[0m54       \u001b[0m | \u001b[0m-0.1179  \u001b[0m | \u001b[0m11.52    \u001b[0m | \u001b[0m5.31     \u001b[0m | \u001b[0m61.85    \u001b[0m | \u001b[0m1.674    \u001b[0m | \u001b[0m5.558    \u001b[0m | \u001b[0m0.0389   \u001b[0m |\n",
            "| \u001b[0m55       \u001b[0m | \u001b[0m-0.1295  \u001b[0m | \u001b[0m11.0     \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m36.88    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
            "=================================================================================================\n",
            "Bayesian Optimization took 31.50 seconds\n",
            "\n",
            "Optimized Input Parameters (Differential Evolution):\n",
            "[12.          3.80566203  4.35811306  3.          4.          3.        ]\n",
            "Predicted Output (Differential Evolution):\n",
            "[[ 1.4360169e-03  5.6929025e-04  8.5819614e-01 -1.0939165e+00]]\n",
            "\n",
            "Optimized Input Parameters (Particle Swarm Optimization):\n",
            "[12.          4.81894527 10.98102086  6.          3.          0.        ]\n",
            "Predicted Output (Particle Swarm Optimization):\n",
            "[[ 9.3383773e-04  5.8866874e-04  7.1554017e-01 -1.2629864e+00]]\n",
            "\n",
            "Optimized Input Parameters (Simulated Annealing):\n",
            "[12.          1.73759295 15.84172875  5.          1.          0.        ]\n",
            "Predicted Output (Simulated Annealing):\n",
            "[[ 9.4636343e-04  5.8122206e-04  7.0701474e-01 -1.2470055e+00]]\n",
            "\n",
            "Optimized Input Parameters (Shgo):\n",
            "[12.     4.75   0.053  4.     6.     3.   ]\n",
            "Predicted Output (Shgo):\n",
            "[[ 1.4642490e-03  5.6435878e-04  8.5954899e-01 -1.0779208e+00]]\n",
            "\n",
            "Optimized Input Parameters (Grid Search):\n",
            "[12, 1, 0.053, 1, 2, 3.0]\n",
            "Predicted Output (Grid Search):\n",
            "[[ 1.4601717e-03  5.7532173e-04  8.7714219e-01 -1.0975486e+00]]\n",
            "\n",
            "Optimized Input Parameters (Bayesian Optimization):\n",
            "[11.0, 1.0, 8.146453974319504, 6.0, 6.0, 0.0]\n",
            "Predicted Output (Bayesian Optimization):\n",
            "[[ 9.3243085e-04  5.8103580e-04  7.0180064e-01 -1.2504731e+00]]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from scipy.optimize import differential_evolution, shgo, dual_annealing\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from bayes_opt import BayesianOptimization\n",
        "from pyswarm import pso\n",
        "import nevergrad as ng\n",
        "import time\n",
        "\n",
        "# Target output\n",
        "target_output = np.array([0.000256, 5.926848e-06, 0.877, -1.50])\n",
        "\n",
        "# Weighted Loss Function\n",
        "def loss_function(x):\n",
        "    x = np.array(x)\n",
        "    x[0] = int(round(x[0]))\n",
        "    x[1] = int(round(x[1]))\n",
        "    x[3] = int(round(x[3]))\n",
        "    x[4] = int(round(x[4]))\n",
        "    x[5] = int(round(x[5]))\n",
        "    x = x.reshape(1, -1)\n",
        "    predicted_output = model.predict(x, verbose=0)\n",
        "    loss = np.mean(np.abs(predicted_output - target_output))\n",
        "    return loss\n",
        "\n",
        "# Define bounds for different types of variables\n",
        "bounds = {\n",
        "    'param1': (11, 14),\n",
        "    'param2': (1, 6),\n",
        "    'param3': (0.053, 100.000),\n",
        "    'param4': (1, 6),\n",
        "    'param5': (1, 6),\n",
        "    'param6': (0, 6)\n",
        "}\n",
        "\n",
        "# Convert bounds to tuple format for SciPy optimization\n",
        "tuple_bounds = [(v[0], v[1]) for v in bounds.values()]\n",
        "\n",
        "# Function to predict output\n",
        "def predict_output(optimized_input):\n",
        "    optimized_input = np.array(optimized_input).reshape(1, -1)\n",
        "    predicted_output = model.predict(optimized_input, verbose=0)\n",
        "    return predicted_output\n",
        "\n",
        "# Optimize using different algorithms\n",
        "def optimize_with_algorithms():\n",
        "    results = {}\n",
        "\n",
        "    # Differential Evolution\n",
        "    start_time = time.time()\n",
        "    result_de = differential_evolution(loss_function, tuple_bounds, maxiter=50, strategy='best1bin')\n",
        "    de_params = result_de.x\n",
        "    de_params[0:1] = np.round(de_params[0:1])\n",
        "    de_params[3:6] = np.round(de_params[3:6])\n",
        "    results['Differential Evolution'] = (de_params, predict_output(de_params))\n",
        "    print(f\"Differential Evolution took {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "    # Particle Swarm Optimization\n",
        "    start_time = time.time()\n",
        "    lb = [b[0] for b in tuple_bounds]\n",
        "    ub = [b[1] for b in tuple_bounds]\n",
        "    optimized_input_pso, _ = pso(loss_function, lb, ub, swarmsize=10, maxiter=50)\n",
        "    optimized_input_pso[0:1] = np.round(optimized_input_pso[0:1])\n",
        "    optimized_input_pso[3:6] = np.round(optimized_input_pso[3:6])\n",
        "    results['Particle Swarm Optimization'] = (optimized_input_pso, predict_output(optimized_input_pso))\n",
        "    print(f\"Particle Swarm Optimization took {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "    # Simulated Annealing\n",
        "    start_time = time.time()\n",
        "    result_sa = dual_annealing(loss_function, bounds=tuple_bounds, maxiter=50)\n",
        "    sa_params = result_sa.x\n",
        "    sa_params[0:1] = np.round(sa_params[0:1])\n",
        "    sa_params[3:6] = np.round(sa_params[3:6])\n",
        "    results['Simulated Annealing'] = (sa_params, predict_output(sa_params))\n",
        "    print(f\"Simulated Annealing took {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "    # Shgo (Simplicial Homology Global Optimization)\n",
        "    start_time = time.time()\n",
        "    result_shgo = shgo(loss_function, bounds=tuple_bounds, iters=50)\n",
        "    shgo_params = result_shgo.x\n",
        "    shgo_params[0:1] = np.round(shgo_params[0:1])\n",
        "    shgo_params[3:6] = np.round(shgo_params[3:6])\n",
        "    results['Shgo'] = (shgo_params, predict_output(shgo_params))\n",
        "    print(f\"Shgo took {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "    # Grid Search\n",
        "    start_time = time.time()\n",
        "    grid = ParameterGrid({\n",
        "        'param1': range(11, 15),\n",
        "        'param2': range(1, 7),\n",
        "        'param3': np.linspace(0.053, 100.000, 3),  # Lower the resolution\n",
        "        'param4': range(1, 7),\n",
        "        'param5': range(1, 7),\n",
        "        'param6': np.linspace(0, 6, 3)  # Lower the resolution\n",
        "    })\n",
        "    best_loss = float('inf')\n",
        "    best_params = None\n",
        "    for params in grid:\n",
        "        x = [params[k] for k in sorted(params.keys())]\n",
        "        loss = loss_function(x)\n",
        "        if loss < best_loss:\n",
        "            best_loss = loss\n",
        "            best_params = x\n",
        "    results['Grid Search'] = (best_params, predict_output(best_params))\n",
        "    print(f\"Grid Search took {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "    # Bayesian Optimization\n",
        "    start_time = time.time()\n",
        "    def bayesian_function(param1, param2, param3, param4, param5, param6):\n",
        "        return -loss_function([param1, param2, param3, param4, param5, param6])\n",
        "\n",
        "    optimizer = BayesianOptimization(\n",
        "        f=bayesian_function,\n",
        "        pbounds={\n",
        "            'param1': bounds['param1'],\n",
        "            'param2': bounds['param2'],\n",
        "            'param3': bounds['param3'],\n",
        "            'param4': bounds['param4'],\n",
        "            'param5': bounds['param5'],\n",
        "            'param6': bounds['param6']\n",
        "        },\n",
        "        random_state=42,\n",
        "        allow_duplicate_points=True  # Allow duplicate points\n",
        "    )\n",
        "    optimizer.maximize(init_points=5, n_iter=50)  # Reduce the number of iterations\n",
        "    best_params_bo = optimizer.max['params']\n",
        "    best_params_bo_array = [best_params_bo[key] for key in sorted(best_params_bo.keys())]\n",
        "    best_params_bo_array[0:1] = np.round(best_params_bo_array[0:1])\n",
        "    best_params_bo_array[3:6] = np.round(best_params_bo_array[3:6])\n",
        "    results['Bayesian Optimization'] = (best_params_bo_array, predict_output(best_params_bo_array))\n",
        "    print(f\"Bayesian Optimization took {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "    return results\n",
        "\n",
        "optimized_results = optimize_with_algorithms()\n",
        "\n",
        "for algo, (params, prediction) in optimized_results.items():\n",
        "    print(f\"\\nOptimized Input Parameters ({algo}):\")\n",
        "    print(params)\n",
        "    print(f\"Predicted Output ({algo}):\")\n",
        "    print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import math\n",
        "\n",
        "# Function to compute performance metrics\n",
        "def compute_metrics(predictions, target):\n",
        "    metrics = {}\n",
        "    metrics['MAE'] = mean_absolute_error(target, predictions)\n",
        "    metrics['MSE'] = mean_squared_error(target, predictions)\n",
        "    metrics['RMSE'] = math.sqrt(metrics['MSE'])\n",
        "    return metrics\n",
        "\n",
        "# Compute metrics for all optimization results\n",
        "metrics_dict = {}\n",
        "for algo, (params, prediction) in optimized_results.items():\n",
        "    metrics_dict[algo] = compute_metrics(prediction[0], target_output)\n",
        "\n",
        "# Convert metrics to a DataFrame for easier plotting\n",
        "import pandas as pd\n",
        "metrics_df = pd.DataFrame(metrics_dict).T\n",
        "\n",
        "# Plot the metrics\n",
        "plt.figure(figsize=(12, 6))\n",
        "metrics_df.plot(kind='bar', figsize=(12, 6))\n",
        "plt.title('Performance Metrics for Different Optimization Algorithms')\n",
        "plt.xlabel('Optimization Algorithm')\n",
        "plt.ylabel('Metric Value')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(loc='upper right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "I61aQsGBd8YM",
        "outputId": "9279bc9b-bc0e-445e-c251-64512670ce14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute and print metrics for all optimization results\n",
        "for algo, (params, prediction) in optimized_results.items():\n",
        "    metrics = compute_metrics(prediction[0], target_output)\n",
        "    print(f\"\\nPerformance Metrics ({algo}):\")\n",
        "    print(f\"MAE: {metrics['MAE']:.6f}\")\n",
        "    print(f\"MSE: {metrics['MSE']:.6f}\")\n",
        "    print(f\"RMSE: {metrics['RMSE']:.6f}\")\n",
        "\n",
        "# Plot the metrics as bar plots\n",
        "plt.figure(figsize=(12, 6))\n",
        "metrics_df.plot(kind='bar', figsize=(12, 6))\n",
        "plt.title('Performance Metrics for Different Optimization Algorithms')\n",
        "plt.xlabel('Optimization Algorithm')\n",
        "plt.ylabel('Metric Value')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(loc='upper right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0T72vfpdeG0V",
        "outputId": "58046f25-4412-4729-8cd0-e2d40e13ecb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Performance Metrics (Differential Evolution):\n",
            "MAE: 0.106658\n",
            "MSE: 0.041315\n",
            "RMSE: 0.203260\n",
            "\n",
            "Performance Metrics (Particle Swarm Optimization):\n",
            "MAE: 0.099933\n",
            "MSE: 0.020561\n",
            "RMSE: 0.143392\n",
            "\n",
            "Performance Metrics (Simulated Annealing):\n",
            "MAE: 0.106061\n",
            "MSE: 0.023226\n",
            "RMSE: 0.152399\n",
            "\n",
            "Performance Metrics (Shgo):\n",
            "MAE: 0.110324\n",
            "MSE: 0.044614\n",
            "RMSE: 0.211221\n",
            "\n",
            "Performance Metrics (Grid Search):\n",
            "MAE: 0.101092\n",
            "MSE: 0.040492\n",
            "RMSE: 0.201227\n",
            "\n",
            "Performance Metrics (Bayesian Optimization):\n",
            "MAE: 0.106494\n",
            "MSE: 0.023240\n",
            "RMSE: 0.152446\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BRKKcYfXMRd"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras import layers, models\n",
        "# import numpy as np\n",
        "\n",
        "# # Sample data\n",
        "# x_data = np.array([\n",
        "#     [6, 0.053, 1, 2, 6],\n",
        "#     [1, 100.0, 3, 4, 0]\n",
        "# ])\n",
        "# y_data = np.array([\n",
        "#     [7e-6, 8.804207e-9, 2.0, -1.68],\n",
        "#     [0.005373, 3.050072e-8, 1.75, -1.0]\n",
        "# ])\n",
        "\n",
        "# # Define the generator model\n",
        "# def build_generator(output_dim):\n",
        "#     model = models.Sequential([\n",
        "#         layers.Dense(256, activation='relu', input_shape=(100,)),\n",
        "#         layers.BatchNormalization(),\n",
        "#         layers.Dense(128, activation='relu'),\n",
        "#         layers.Dense(output_dim, activation='linear')\n",
        "#     ])\n",
        "#     return model\n",
        "\n",
        "# # Define the discriminator model\n",
        "# def build_discriminator(input_dim):\n",
        "#     model = models.Sequential([\n",
        "#         layers.Dense(256, activation='relu', input_shape=(input_dim,)),\n",
        "#         layers.BatchNormalization(),\n",
        "#         layers.Dense(128, activation='relu'),\n",
        "#         layers.Dense(1, activation='linear')\n",
        "#     ])\n",
        "#     return model\n",
        "\n",
        "\n",
        "# # Compile the GAN\n",
        "# def build_gan(generator, discriminator):\n",
        "#     discriminator.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "#     discriminator.trainable = False\n",
        "#     gan_input = layers.Input(shape=(100,))\n",
        "#     generated_input = generator(gan_input)\n",
        "#     combined_input = layers.Concatenate()([gan_input, generated_input])\n",
        "#     gan_output = discriminator(combined_input)\n",
        "#     gan = models.Model(gan_input, gan_output)\n",
        "#     gan.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "#     return gan\n",
        "\n",
        "# # Custom rounding function\n",
        "# def round_params(generated_params):\n",
        "#     generated_params[:, :2] = np.round(generated_params[:, :2])\n",
        "#     generated_params[:, 3:] = np.round(generated_params[:, 3:])\n",
        "#     return generated_params\n",
        "\n",
        "# # Build and compile the models\n",
        "# generator = build_generator(output_dim=x_data.shape[1])\n",
        "# discriminator_input_dim = x_data.shape[1] + y_data.shape[1]\n",
        "# discriminator = build_discriminator(input_dim=discriminator_input_dim)\n",
        "\n",
        "# gan = build_gan(generator, discriminator)\n",
        "\n",
        "# # Training the GAN\n",
        "# epochs = 10000\n",
        "# batch_size = 2\n",
        "\n",
        "# for epoch in range(epochs):\n",
        "#     # Train the discriminator\n",
        "#     idx = np.random.randint(0, x_data.shape[0], batch_size)\n",
        "#     real_inputs = x_data[idx]\n",
        "#     real_outputs = y_data[idx]\n",
        "#     noise = np.random.normal(0, 1, (batch_size, 100))\n",
        "#     generated_inputs = generator.predict(noise)\n",
        "#     generated_inputs = round_params(generated_inputs)\n",
        "#     real_pairs = np.concatenate([real_inputs, real_outputs], axis=1)\n",
        "#     generated_pairs = np.concatenate([noise, generated_inputs], axis=1)\n",
        "\n",
        "#     d_loss_real = discriminator.train_on_batch(real_pairs, np.ones((batch_size, 1)))\n",
        "#     d_loss_fake = discriminator.train_on_batch(generated_pairs, np.zeros((batch_size, 1)))\n",
        "#     d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "#     # Train the generator\n",
        "#     noise = np.random.normal(0, 1, (batch_size, 100))\n",
        "#     g_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n",
        "\n",
        "#     if epoch % 1000 == 0:\n",
        "#         print(f\"{epoch} [D loss: {d_loss}] [G loss: {g_loss}]\")\n",
        "\n",
        "# # Inverse design: generate input parameters given a desired output\n",
        "# desired_output = np.array([[0.001, 1e-08, 2.0, -1.5]])  # Example desired output\n",
        "# noise = np.random.normal(0, 1, (1, 100))\n",
        "# generated_input = generator.predict(noise)\n",
        "# generated_input = round_params(generated_input)\n",
        "# print(\"Generated input parameters for desired output:\", generated_input)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUrgb2wbYMJq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "# Generator Model\n",
        "def build_generator(input_dim, output_dim):\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Dense(128, activation='relu', input_dim=input_dim),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dense(output_dim, activation='linear')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Discriminator Model\n",
        "def build_discriminator(input_dim):\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Dense(512, activation='leaky_relu', input_dim=input_dim),\n",
        "        layers.Dense(256, activation='leaky_relu'),\n",
        "        layers.Dense(1, activation='linear')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Hyperparameters\n",
        "z_dim = 100  # Dimension of the noise input to the generator\n",
        "data_dim = 6  # Dimension of the data\n",
        "\n",
        "# Initialize the models\n",
        "generator = build_generator(z_dim, data_dim)\n",
        "discriminator = build_discriminator(data_dim)\n",
        "\n",
        "# Compile the discriminator\n",
        "discriminator.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), loss='mse')\n",
        "\n",
        "# Build and compile the GAN model\n",
        "discriminator.trainable = False\n",
        "\n",
        "gan_input = layers.Input(shape=(z_dim,))\n",
        "generated_data = generator(gan_input)\n",
        "gan_output = discriminator(generated_data)\n",
        "\n",
        "gan = tf.keras.models.Model(gan_input, gan_output)\n",
        "gan.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), loss='mse')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of epochs\n",
        "num_epochs = 100\n",
        "batch_size = 64\n",
        "\n",
        "# # Example dataset (update this with your actual data)\n",
        "# x = np.array([\n",
        "#     [11, 6, 0.053, 1, 2, 6],\n",
        "#     [12, 1, 100.000, 3, 4, 0],\n",
        "#     [13, 1, 100.000, 3, 5, 4],\n",
        "#     [14, 3, 1.000, 6, 1, 0],\n",
        "#     [14, 5, 1.000, 6, 1, 0],\n",
        "#     [14, 7, 1.000, 6, 1, 0]\n",
        "# ])\n",
        "\n",
        "# Function to generate real data from your dataset\n",
        "def get_real_data():\n",
        "    return x\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Train Discriminator\n",
        "    real_data = get_real_data()\n",
        "    batch_size_real = real_data.shape[0]\n",
        "\n",
        "    labels_real = np.ones((batch_size_real, 1))\n",
        "    labels_fake = np.zeros((batch_size_real, 1))\n",
        "\n",
        "    d_loss_real = discriminator.train_on_batch(real_data, labels_real)\n",
        "\n",
        "    z = np.random.normal(0, 1, (batch_size_real, z_dim))\n",
        "    fake_data = generator.predict(z)\n",
        "\n",
        "    d_loss_fake = discriminator.train_on_batch(fake_data, labels_fake)\n",
        "\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "    # Train Generator\n",
        "    z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "    labels_gan = np.ones((batch_size, 1))\n",
        "\n",
        "    g_loss = gan.train_on_batch(z, labels_gan)\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch [{epoch}/{num_epochs}], d_loss: {d_loss}, g_loss: {g_loss}')\n",
        "\n",
        "print(\"Training completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFL77BlvN2Gj",
        "outputId": "9d9e28c5-9068-49aa-8335-1baf60d1a53b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n",
            "Epoch [0/1000], d_loss: 0.08519823162350804, g_loss: 0.9100799560546875\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Epoch [100/1000], d_loss: 0.28886501491069794, g_loss: 0.9236549139022827\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Epoch [200/1000], d_loss: 0.21085740998387337, g_loss: 0.7645223140716553\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Epoch [300/1000], d_loss: 0.2273121327161789, g_loss: 0.61153244972229\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "1/1 [==============================] - 0s 148ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 139ms/step\n",
            "Epoch [400/1000], d_loss: 0.2287823185324669, g_loss: 0.6133699417114258\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Epoch [500/1000], d_loss: 0.2335568144917488, g_loss: 0.5387319326400757\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Epoch [600/1000], d_loss: 0.23354681581258774, g_loss: 0.5981482863426208\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Epoch [700/1000], d_loss: 0.22012733295559883, g_loss: 0.5190013647079468\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Epoch [800/1000], d_loss: 0.19149081408977509, g_loss: 0.6077076196670532\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Epoch [900/1000], d_loss: 0.18647871538996696, g_loss: 0.6246613264083862\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 152ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Training completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define bounds\n",
        "bounds = {\n",
        "    'param1': (11, 14),\n",
        "    'param2': (1, 6),\n",
        "    'param3': (0.053, 100.000),\n",
        "    'param4': (1, 6),\n",
        "    'param5': (1, 6),\n",
        "    'param6': (0, 6)\n",
        "}\n",
        "\n",
        "# Function to post-process the generated samples\n",
        "def post_process_samples(samples, bounds):\n",
        "    samples[:, 0] = np.clip(np.round(samples[:, 0]), bounds['param1'][0], bounds['param1'][1])\n",
        "    samples[:, 1] = np.clip(np.round(samples[:, 1]), bounds['param2'][0], bounds['param2'][1])\n",
        "    samples[:, 2] = np.clip(samples[:, 2], bounds['param3'][0], bounds['param3'][1])\n",
        "    samples[:, 3] = np.clip(np.round(samples[:, 3]), bounds['param4'][0], bounds['param4'][1])\n",
        "    samples[:, 4] = np.clip(np.round(samples[:, 4]), bounds['param5'][0], bounds['param5'][1])\n",
        "    samples[:, 5] = np.clip(np.round(samples[:, 5]), bounds['param6'][0], bounds['param6'][1])\n",
        "    return samples\n",
        "\n",
        "# Generate new samples\n",
        "# z = np.random.normal(0, 1, (10, z_dim))  # Generate 10 new samples\n",
        "z = np.array([0.1,0.2,0.3,0.4])\n",
        "generated_samples = generator.predict(z)\n",
        "\n",
        "# Post-process the generated samples\n",
        "processed_samples = post_process_samples(generated_samples, bounds)\n",
        "\n",
        "print(\"Generated Samples:\")\n",
        "print(processed_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dyOX2DnYN4A6",
        "outputId": "7d641d3a-9906-4520-a948-8aa33c15322e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node sequential_24/dense_91/MatMul defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-45-2e9a592f5a8c>\", line 24, in <cell line: 24>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2655, in predict\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2440, in predict_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2425, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2413, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2381, in predict_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/sequential.py\", line 398, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py\", line 241, in call\n\nIn[0] ndims must be >= 2: 1\n\t [[{{node sequential_24/dense_91/MatMul}}]] [Op:__inference_predict_function_375542]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-2e9a592f5a8c>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# z = np.random.normal(0, 1, (10, z_dim))  # Generate 10 new samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mgenerated_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Post-process the generated samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sequential_24/dense_91/MatMul defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-45-2e9a592f5a8c>\", line 24, in <cell line: 24>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2655, in predict\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2440, in predict_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2425, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2413, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2381, in predict_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/sequential.py\", line 398, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py\", line 241, in call\n\nIn[0] ndims must be >= 2: 1\n\t [[{{node sequential_24/dense_91/MatMul}}]] [Op:__inference_predict_function_375542]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# INT\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "# Custom activation layer for integer output\n",
        "class IntegerActivation(layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        return tf.round(inputs)\n",
        "\n",
        "# Generator Model\n",
        "def build_generator(input_dim, output_dim):\n",
        "    input_layer = layers.Input(shape=(input_dim,))\n",
        "\n",
        "    x = layers.Dense(128, activation='relu')(input_layer)\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.Dense(512, activation='relu')(x)\n",
        "\n",
        "    param1 = layers.Dense(1, activation='linear')(x)\n",
        "    param2 = layers.Dense(1, activation='linear')(x)\n",
        "    param3 = layers.Dense(1, activation='linear')(x)  # Float value, no activation change\n",
        "    param4 = layers.Dense(1, activation='linear')(x)\n",
        "    param5 = layers.Dense(1, activation='linear')(x)\n",
        "    param6 = layers.Dense(1, activation='linear')(x)\n",
        "\n",
        "    param1 = IntegerActivation()(param1)\n",
        "    param2 = IntegerActivation()(param2)\n",
        "    param4 = IntegerActivation()(param4)\n",
        "    param5 = IntegerActivation()(param5)\n",
        "    param6 = IntegerActivation()(param6)\n",
        "\n",
        "    output_layer = layers.Concatenate()([param1, param2, param3, param4, param5, param6])\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "    return model\n",
        "\n",
        "# Discriminator Model\n",
        "def build_discriminator(input_dim):\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Dense(512, activation='leaky_relu', input_dim=input_dim),\n",
        "        layers.Dense(256, activation='leaky_relu'),\n",
        "        layers.Dense(1, activation='linear')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Hyperparameters\n",
        "z_dim = 100  # Dimension of the noise input to the generator\n",
        "data_dim = 6  # Dimension of the data\n",
        "\n",
        "# Initialize the models\n",
        "generator = build_generator(z_dim, data_dim)\n",
        "discriminator = build_discriminator(data_dim)\n",
        "\n",
        "# Compile the discriminator\n",
        "discriminator.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), loss='mse')\n",
        "\n",
        "# Build and compile the GAN model\n",
        "discriminator.trainable = False\n",
        "\n",
        "gan_input = layers.Input(shape=(z_dim,))\n",
        "generated_data = generator(gan_input)\n",
        "gan_output = discriminator(generated_data)\n",
        "\n",
        "gan = tf.keras.models.Model(gan_input, gan_output)\n",
        "gan.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), loss='mse')\n"
      ],
      "metadata": {
        "id": "3L9muUuKSfCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of epochs\n",
        "num_epochs = 100\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "# Normalize the float column (param3) for better performance\n",
        "x[:, 2] = (x[:, 2] - 0.053) / (100.000 - 0.053)\n",
        "\n",
        "# Function to generate real data from your dataset\n",
        "def get_real_data():\n",
        "    return x\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Train Discriminator\n",
        "    real_data = get_real_data()\n",
        "    batch_size_real = real_data.shape[0]\n",
        "\n",
        "    labels_real = np.ones((batch_size_real, 1))\n",
        "    labels_fake = np.zeros((batch_size_real, 1))\n",
        "\n",
        "    d_loss_real = discriminator.train_on_batch(real_data, labels_real)\n",
        "\n",
        "    z = np.random.normal(0, 1, (batch_size_real, z_dim))\n",
        "    fake_data = generator.predict(z)\n",
        "\n",
        "    d_loss_fake = discriminator.train_on_batch(fake_data, labels_fake)\n",
        "\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "    # Train Generator\n",
        "    z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "    labels_gan = np.ones((batch_size, 1))\n",
        "\n",
        "    g_loss = gan.train_on_batch(z, labels_gan)\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch [{epoch}/{num_epochs}], d_loss: {d_loss}, g_loss: {g_loss}')\n",
        "\n",
        "print(\"Training completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-pJcU8hl4Zs",
        "outputId": "f6b25229-f7b3-4564-cd85-04b85c2b15c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 211ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_22/kernel:0', 'dense_22/bias:0', 'dense_23/kernel:0', 'dense_23/bias:0', 'dense_25/kernel:0', 'dense_25/bias:0', 'dense_26/kernel:0', 'dense_26/bias:0', 'dense_27/kernel:0', 'dense_27/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_22/kernel:0', 'dense_22/bias:0', 'dense_23/kernel:0', 'dense_23/bias:0', 'dense_25/kernel:0', 'dense_25/bias:0', 'dense_26/kernel:0', 'dense_26/bias:0', 'dense_27/kernel:0', 'dense_27/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_22/kernel:0', 'dense_22/bias:0', 'dense_23/kernel:0', 'dense_23/bias:0', 'dense_25/kernel:0', 'dense_25/bias:0', 'dense_26/kernel:0', 'dense_26/bias:0', 'dense_27/kernel:0', 'dense_27/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_22/kernel:0', 'dense_22/bias:0', 'dense_23/kernel:0', 'dense_23/bias:0', 'dense_25/kernel:0', 'dense_25/bias:0', 'dense_26/kernel:0', 'dense_26/bias:0', 'dense_27/kernel:0', 'dense_27/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/100], d_loss: 0.1506273306440562, g_loss: 0.9611825942993164\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 131ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Training completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define bounds\n",
        "bounds = {\n",
        "    'param1': (11, 14),\n",
        "    'param2': (1, 6),\n",
        "    'param3': (0.053, 100.000),\n",
        "    'param4': (1, 6),\n",
        "    'param5': (1, 6),\n",
        "    'param6': (0, 6)\n",
        "}\n",
        "\n",
        "# Function to post-process the generated samples\n",
        "def post_process_samples(samples, bounds):\n",
        "    samples[:, 0] = np.clip(samples[:, 0], bounds['param1'][0], bounds['param1'][1])\n",
        "    samples[:, 1] = np.clip(samples[:, 1], bounds['param2'][0], bounds['param2'][1])\n",
        "    samples[:, 2] = samples[:, 2] * (bounds['param3'][1] - bounds['param3'][0]) + bounds['param3'][0]  # Denormalize\n",
        "    samples[:, 3] = np.clip(samples[:, 3], bounds['param4'][0], bounds['param4'][1])\n",
        "    samples[:, 4] = np.clip(samples[:, 4], bounds['param5'][0], bounds['param5'][1])\n",
        "    samples[:, 5] = np.clip(samples[:, 5], bounds['param6'][0], bounds['param6'][1])\n",
        "    return samples\n",
        "\n",
        "# Generate new samples\n",
        "z = np.random.normal(0, 1, (10, z_dim))  # Generate 10 new samples\n",
        "generated_samples = generator.predict(z)\n",
        "\n",
        "# Post-process the generated samples\n",
        "processed_samples = post_process_samples(generated_samples, bounds)\n",
        "\n",
        "print(\"Generated Samples:\")\n",
        "print(processed_samples)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NswfF8V2l6Uq",
        "outputId": "f76efacc-42be-4856-d170-ebb5aafa78eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "Generated Samples:\n",
            "[[11.        1.       42.28343   1.        1.        0.      ]\n",
            " [11.        1.       20.684832  1.        1.        0.      ]\n",
            " [11.        1.       26.448273  1.        1.        0.      ]\n",
            " [11.        1.       18.103437  1.        1.        0.      ]\n",
            " [11.        1.       50.125523  1.        1.        0.      ]\n",
            " [11.        1.       46.149002  1.        1.        0.      ]\n",
            " [11.        1.       17.235891  1.        1.        0.      ]\n",
            " [11.        1.       24.77718   1.        1.        0.      ]\n",
            " [11.        1.       36.967644  1.        1.        0.      ]\n",
            " [11.        1.       70.83195   1.        1.        0.      ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "lpTnlV4ll8oX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "ad9bc155-d6a5-4536-a5ab-48680ba7d2ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   mname  mthickness (nm)  cellarea (m2)  topelectrode  bottomelectrode  \\\n",
              "0     11                6           0.053             1                2   \n",
              "1     12                1         100.000             3                4   \n",
              "2     13                1         100.000             3                5   \n",
              "3     14                3           1.000             6                1   \n",
              "4     14                5           1.000             6                1   \n",
              "5     14                7           1.000             6                1   \n",
              "\n",
              "   extrastack  \n",
              "0           6  \n",
              "1           0  \n",
              "2           4  \n",
              "3           0  \n",
              "4           0  \n",
              "5           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33ad0fe3-27db-42ee-b322-91da991f916a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mname</th>\n",
              "      <th>mthickness (nm)</th>\n",
              "      <th>cellarea (m2)</th>\n",
              "      <th>topelectrode</th>\n",
              "      <th>bottomelectrode</th>\n",
              "      <th>extrastack</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>0.053</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>100.000</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>100.000</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>1.000</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>1.000</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "      <td>1.000</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33ad0fe3-27db-42ee-b322-91da991f916a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-33ad0fe3-27db-42ee-b322-91da991f916a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-33ad0fe3-27db-42ee-b322-91da991f916a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-14b4978b-d7c3-456b-b101-6e623ff206be\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-14b4978b-d7c3-456b-b101-6e623ff206be')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-14b4978b-d7c3-456b-b101-6e623ff206be button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_0130286c-9750-47a5-800e-963a581a491c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('x')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0130286c-9750-47a5-800e-963a581a491c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('x');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x",
              "summary": "{\n  \"name\": \"x\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"mname\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 11,\n        \"max\": 14,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          12,\n          14,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mthickness (nm)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 7,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          7,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cellarea (\\u00b5m2)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 51.246949842567865,\n        \"min\": 0.053,\n        \"max\": 100.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.053,\n          100.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topelectrode\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          3,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bottomelectrode\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"extrastack\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          6,\n          0,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "BVWt0HHrqu4P",
        "outputId": "919fa7c6-1cf2-4d34-ca02-85d4c59edf39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    roff_rv        ron_rv     vs    vr\n",
              "0  0.000007  8.804207e-09  2.000 -1.68\n",
              "1  0.005373  3.050072e-08  1.750 -1.00\n",
              "2  0.000663  3.682850e-08  0.750 -0.75\n",
              "3  0.000256  5.926848e-06  0.877 -1.50\n",
              "4  0.000407  2.387368e-05  0.580 -1.50\n",
              "5  0.000647  1.113548e-04  0.660 -1.50"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3e6b2ab5-a5a4-46cd-a04d-3b7c7da6243b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>roff_rv</th>\n",
              "      <th>ron_rv</th>\n",
              "      <th>vs</th>\n",
              "      <th>vr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000007</td>\n",
              "      <td>8.804207e-09</td>\n",
              "      <td>2.000</td>\n",
              "      <td>-1.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.005373</td>\n",
              "      <td>3.050072e-08</td>\n",
              "      <td>1.750</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000663</td>\n",
              "      <td>3.682850e-08</td>\n",
              "      <td>0.750</td>\n",
              "      <td>-0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000256</td>\n",
              "      <td>5.926848e-06</td>\n",
              "      <td>0.877</td>\n",
              "      <td>-1.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000407</td>\n",
              "      <td>2.387368e-05</td>\n",
              "      <td>0.580</td>\n",
              "      <td>-1.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.000647</td>\n",
              "      <td>1.113548e-04</td>\n",
              "      <td>0.660</td>\n",
              "      <td>-1.50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e6b2ab5-a5a4-46cd-a04d-3b7c7da6243b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3e6b2ab5-a5a4-46cd-a04d-3b7c7da6243b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3e6b2ab5-a5a4-46cd-a04d-3b7c7da6243b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b0b293ed-459b-42cc-82e2-0f284ce68745\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b0b293ed-459b-42cc-82e2-0f284ce68745')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b0b293ed-459b-42cc-82e2-0f284ce68745 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d14be967-f043-478e-80da-14d32267b7e4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('y')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d14be967-f043-478e-80da-14d32267b7e4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('y');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "y",
              "summary": "{\n  \"name\": \"y\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"roff_rv\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0020469973172576564,\n        \"min\": 7.18116144058856e-06,\n        \"max\": 0.00537337589369173,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          7.18116144058856e-06,\n          0.00537337589369173,\n          0.00064720272876936\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ron_rv\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.400135177848422e-05,\n        \"min\": 8.80420741713041e-09,\n        \"max\": 0.000111354848017854,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          8.80420741713041e-09,\n          3.05007199370124e-08,\n          0.000111354848017854\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6113396491858406,\n        \"min\": 0.58,\n        \"max\": 2.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          2.0,\n          1.75,\n          0.66\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.36168586738586656,\n        \"min\": -1.68,\n        \"max\": -0.75,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -1.0,\n          -1.5,\n          -1.68\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "# Generator Model\n",
        "def build_generator(input_dim, output_dim):\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Dense(128, activation='relu', input_dim=input_dim),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dense(output_dim, activation='linear')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Discriminator Model\n",
        "def build_discriminator(input_dim):\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Dense(512, activation='leaky_relu', input_dim=input_dim),\n",
        "        layers.Dense(256, activation='leaky_relu'),\n",
        "        layers.Dense(1, activation='linear')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Hyperparameters\n",
        "z_dim = 100  # Dimension of the noise input to the generator\n",
        "input_dim = 4  # Dimension of input parameters\n",
        "output_dim = 6  # Dimension of output parameters\n",
        "\n",
        "# Initialize the models\n",
        "generator = build_generator(z_dim, output_dim)  # Note: input_dim is z_dim for the generator\n",
        "discriminator = build_discriminator(output_dim)\n",
        "\n",
        "# Compile the discriminator\n",
        "discriminator.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), loss='mse')\n",
        "\n",
        "# Build and compile the GAN model\n",
        "discriminator.trainable = False\n",
        "\n",
        "# Define bounds for post-processing\n",
        "bounds = {\n",
        "    'param1': (11, 14),\n",
        "    'param2': (1, 6),\n",
        "    'param3': (0.053, 100.000),\n",
        "    'param4': (1, 6),\n",
        "    'param5': (1, 6),\n",
        "    'param6': (0, 6)\n",
        "}\n",
        "\n",
        "# Function to post-process the generated samples\n",
        "def post_process_samples(samples, bounds):\n",
        "    samples[:, 0] = np.clip(np.round(samples[:, 0]), bounds['param1'][0], bounds['param1'][1])\n",
        "    samples[:, 1] = np.clip(np.round(samples[:, 1]), bounds['param2'][0], bounds['param2'][1])\n",
        "    samples[:, 2] = np.clip(samples[:, 2], bounds['param3'][0], bounds['param3'][1])\n",
        "    samples[:, 3] = np.clip(np.round(samples[:, 3]), bounds['param4'][0], bounds['param4'][1])\n",
        "    samples[:, 4] = np.clip(np.round(samples[:, 4]), bounds['param5'][0], bounds['param5'][1])\n",
        "    samples[:, 5] = np.clip(np.round(samples[:, 5]), bounds['param6'][0], bounds['param6'][1])\n",
        "    return samples\n",
        "\n",
        "# Inverse design function\n",
        "def inverse_design(generator, target_output, z_dim, learning_rate=0.001, steps=1000):\n",
        "    # Initialize a latent vector\n",
        "    z = tf.Variable(np.random.normal(0, 1, (1, z_dim)), dtype=tf.float32)\n",
        "\n",
        "    # Define the optimizer\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "    # Define the loss function\n",
        "    def loss_fn():\n",
        "        generated_output = generator(z)\n",
        "        return tf.reduce_mean(tf.square(generated_output - target_output))\n",
        "\n",
        "    # Optimization loop\n",
        "    for step in range(steps):\n",
        "        optimizer.minimize(loss_fn, var_list=[z])\n",
        "        if step % 100 == 0:\n",
        "            loss_value = loss_fn().numpy()\n",
        "            print(f'Step {step}, Loss: {loss_value}')\n",
        "\n",
        "    # Get the optimized latent vector and generated output\n",
        "    optimized_z = z.numpy()\n",
        "    generated_output = generator(optimized_z).numpy()\n",
        "    return optimized_z, generated_output\n",
        "\n",
        "# Example target output (adjust as needed)\n",
        "target_output = np.array([[ 11, 6, 0.053, 1, 2, 6]])\n",
        "\n",
        "# Perform inverse design\n",
        "optimized_z, generated_output = inverse_design(generator, target_output, z_dim)\n",
        "\n",
        "# Post-process the generated output\n",
        "processed_output = post_process_samples(generated_output, bounds)\n",
        "\n",
        "print(\"Target Output:\")\n",
        "print(target_output)\n",
        "print(\"Generated Output:\")\n",
        "print(processed_output)\n",
        "\n",
        "# Save the GAN model\n",
        "generator.save('saved_models/generator_model.h5')\n",
        "discriminator.save('saved_models/discriminator_model.h5')\n",
        "\n",
        "print(\"GAN models saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5Ihq4IbqvLK",
        "outputId": "2fdc712d-ac4d-42d2-9d9c-be252527b593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0, Loss: 32.25944900512695\n",
            "Step 100, Loss: 31.35838508605957\n",
            "Step 200, Loss: 30.6011905670166\n",
            "Step 300, Loss: 29.995622634887695\n",
            "Step 400, Loss: 29.460176467895508\n",
            "Step 500, Loss: 28.987661361694336\n",
            "Step 600, Loss: 28.55036735534668\n",
            "Step 700, Loss: 28.144819259643555\n",
            "Step 800, Loss: 27.70709228515625\n",
            "Step 900, Loss: 27.224390029907227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Output:\n",
            "[[11.     6.     0.053  1.     2.     6.   ]]\n",
            "Generated Output:\n",
            "[[11.     1.     0.053  1.     1.     1.   ]]\n",
            "GAN models saved.\n",
            "Object `added` not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Generator Model (assuming z_dim is 100)\n",
        "def build_generator(z_dim, output_dim):\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Dense(128, activation='relu', input_dim=z_dim),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dense(output_dim, activation='linear')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Load trained generator model\n",
        "def load_generator_model():\n",
        "    generator = build_generator(100, 6)  # Assuming z_dim is 100 and output_dim is 6\n",
        "    generator.load_weights('saved_models/generator_model.h5')  # Adjust path to weights\n",
        "    return generator\n",
        "\n",
        "# Load trained generator model\n",
        "generator = load_generator_model()\n",
        "\n",
        "# Example input with 100-dimensional noise vector (adjust as per your requirements)\n",
        "input_params = np.random.normal(0, 1, size=(1, 100))  # Adjust size as per your requirements\n",
        "\n",
        "# Generate predictions\n",
        "generated_output = generator.predict(input_params)\n",
        "\n",
        "# Function to post-process the generated samples (assuming you have it from previous code)\n",
        "def post_process_samples(samples, bounds):\n",
        "    samples[:, 0] = np.clip(np.round(samples[:, 0]), bounds['param1'][0], bounds['param1'][1])\n",
        "    samples[:, 1] = np.clip(np.round(samples[:, 1]), bounds['param2'][0], bounds['param2'][1])\n",
        "    samples[:, 2] = np.clip(samples[:, 2], bounds['param3'][0], bounds['param3'][1])\n",
        "    samples[:, 3] = np.clip(np.round(samples[:, 3]), bounds['param4'][0], bounds['param4'][1])\n",
        "    samples[:, 4] = np.clip(np.round(samples[:, 4]), bounds['param5'][0], bounds['param5'][1])\n",
        "    samples[:, 5] = np.clip(np.round(samples[:, 5]), bounds['param6'][0], bounds['param6'][1])\n",
        "    return samples\n",
        "\n",
        "# Example bounds for post-processing (adjust as per your requirements)\n",
        "bounds = {\n",
        "    'param1': (11, 14),\n",
        "    'param2': (1, 6),\n",
        "    'param3': (0.053, 100.000),\n",
        "    'param4': (1, 6),\n",
        "    'param5': (1, 6),\n",
        "    'param6': (0, 6)\n",
        "}\n",
        "\n",
        "# Post-process the generated output\n",
        "processed_output = post_process_samples(generated_output, bounds)\n",
        "\n",
        "# Print generated output\n",
        "print(\"Generated Output:\")\n",
        "print(processed_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SlOkPLKrHz_",
        "outputId": "4f32f8ca-b63f-46ab-c0c0-3e136633d343"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 121ms/step\n",
            "Generated Output:\n",
            "[[11.        1.        0.271343  1.        1.        0.      ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Function to build your generator model (assuming you have it defined)\n",
        "def build_generator(input_dim, output_dim):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(128, activation='relu', input_dim=input_dim),\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dense(output_dim, activation='linear')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Function to load your trained generator model\n",
        "def load_generator_model():\n",
        "    generator = build_generator(input_dim=4, output_dim=6)  # Adjust input_dim and output_dim as per your trained model\n",
        "    generator.load_weights('/content/saved_models/generator_model.h5')  # Adjust path to weights\n",
        "    return generator\n",
        "\n",
        "# Load trained generator model\n",
        "generator = load_generator_model()\n",
        "\n",
        "# Example input with 4 parameters (you can modify this as needed)\n",
        "input_params = np.array([0.1,0.2,0.3,0.4])  # Generates random input with 4 dimensions\n",
        "\n",
        "# Generate predictions\n",
        "generated_output = generator.predict(input_params)\n",
        "\n",
        "# Print generated output\n",
        "print(\"Generated Output:\")\n",
        "print(generated_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "4huuLnnbwqf6",
        "outputId": "034812c8-b450-417e-c27c-6ead8cc4dfcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_25' (type Sequential).\n    \n    Input 0 of layer \"dense_95\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer 'sequential_25' (type Sequential):\n       inputs=tf.Tensor(shape=(None,), dtype=float32)\n       training=False\n       mask=None\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-d46faf5116a4>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Generate predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mgenerated_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Print generated output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_25' (type Sequential).\n    \n    Input 0 of layer \"dense_95\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer 'sequential_25' (type Sequential):\n       inputs=tf.Tensor(shape=(None,), dtype=float32)\n       training=False\n       mask=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QT3oksZ3y8Ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "inPWEjDzHSO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Generator Model\n",
        "def build_generator(input_dim, output_dim):\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Dense(128, activation='relu', input_dim=input_dim),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dense(output_dim, activation='linear')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Discriminator Model\n",
        "def build_discriminator(input_dim):\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Dense(512, activation='leaky_relu', input_dim=input_dim),\n",
        "        layers.Dense(256, activation='leaky_relu'),\n",
        "        layers.Dense(1, activation='linear')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Hyperparameters\n",
        "input_dim = 4  # Dimension of input parameters\n",
        "output_dim = 6  # Dimension of output parameters\n",
        "\n",
        "# Initialize the models\n",
        "generator = build_generator(input_dim, output_dim)\n",
        "discriminator = build_discriminator(output_dim)\n",
        "\n",
        "# Compile the discriminator\n",
        "discriminator.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), loss='mse')\n",
        "\n",
        "# Build and compile the GAN model\n",
        "discriminator.trainable = False\n",
        "\n",
        "# Define bounds for post-processing\n",
        "bounds = {\n",
        "    'param1': (11, 14),\n",
        "    'param2': (1, 6),\n",
        "    'param3': (0.053, 100.000),\n",
        "    'param4': (1, 6),\n",
        "    'param5': (1, 6),\n",
        "    'param6': (0, 6)\n",
        "}\n",
        "\n",
        "# Function to post-process the generated samples\n",
        "def post_process_samples(samples, bounds):\n",
        "    samples[:, 0] = np.clip(np.round(samples[:, 0]), bounds['param1'][0], bounds['param1'][1])\n",
        "    samples[:, 1] = np.clip(np.round(samples[:, 1]), bounds['param2'][0], bounds['param2'][1])\n",
        "    samples[:, 2] = np.clip(samples[:, 2], bounds['param3'][0], bounds['param3'][1])\n",
        "    samples[:, 3] = np.clip(np.round(samples[:, 3]), bounds['param4'][0], bounds['param4'][1])\n",
        "    samples[:, 4] = np.clip(np.round(samples[:, 4]), bounds['param5'][0], bounds['param5'][1])\n",
        "    samples[:, 5] = np.clip(np.round(samples[:, 5]), bounds['param6'][0], bounds['param6'][1])\n",
        "    return samples\n",
        "\n",
        "# Inverse design function\n",
        "def inverse_design(generator, target_output, input_dim, learning_rate=0.001, steps=1000):\n",
        "    # Initialize a latent vector\n",
        "    z = tf.Variable(np.random.normal(0, 1, (1, input_dim)), dtype=tf.float32)\n",
        "\n",
        "    # Define the optimizer\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "    # Define the loss function\n",
        "    def loss_fn():\n",
        "        generated_output = generator(z)\n",
        "        return tf.reduce_mean(tf.square(generated_output - target_output))\n",
        "\n",
        "    # Optimization loop\n",
        "    for step in range(steps):\n",
        "        optimizer.minimize(loss_fn, var_list=[z])\n",
        "        if step % 100 == 0:\n",
        "            loss_value = loss_fn().numpy()\n",
        "            print(f'Step {step}, Loss: {loss_value}')\n",
        "\n",
        "    # Get the optimized latent vector and generated output\n",
        "    optimized_z = z.numpy()\n",
        "    generated_output = generator(optimized_z).numpy()\n",
        "    return optimized_z, generated_output\n",
        "\n",
        "# Example target output (adjust as needed)\n",
        "target_output = np.array([[ 11, 6, 0.053, 1, 2, 6]])\n",
        "\n",
        "# Perform inverse design\n",
        "optimized_z, generated_output = inverse_design(generator, target_output, input_dim)\n",
        "\n",
        "# Post-process the generated output\n",
        "processed_output = post_process_samples(generated_output, bounds)\n",
        "\n",
        "print(\"Target Output:\")\n",
        "print(target_output)\n",
        "print(\"Generated Output:\")\n",
        "print(processed_output)\n",
        "\n",
        "# Save the GAN model\n",
        "generator.save('saved_models/generator_model.h5')\n",
        "discriminator.save('saved_models/discriminator_model.h5')\n",
        "\n",
        "print(\"GAN models saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMM0c2lOHSSD",
        "outputId": "bf4b9fe7-fc1e-4bca-89d3-8f1a7a361b63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0, Loss: 33.94606018066406\n",
            "Step 100, Loss: 33.870723724365234\n",
            "Step 200, Loss: 33.79981231689453\n",
            "Step 300, Loss: 33.73267364501953\n",
            "Step 400, Loss: 33.66493606567383\n",
            "Step 500, Loss: 33.612464904785156\n",
            "Step 600, Loss: 33.5617561340332\n",
            "Step 700, Loss: 33.512210845947266\n",
            "Step 800, Loss: 33.46010971069336\n",
            "Step 900, Loss: 33.4111328125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Output:\n",
            "[[11.     6.     0.053  1.     2.     6.   ]]\n",
            "Generated Output:\n",
            "[[11.     1.     0.053  1.     1.     0.   ]]\n",
            "GAN models saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load your trained generator model\n",
        "def load_generator_model():\n",
        "    generator = build_generator(input_dim=4, output_dim=6)  # Adjust input_dim and output_dim as per your trained model\n",
        "    generator.load_weights('/content/saved_models/generator_model.h5')  # Adjust path to weights\n",
        "    return generator\n",
        "\n",
        "# Load trained generator model\n",
        "generator = load_generator_model()\n",
        "\n",
        "# Example input with 4 parameters\n",
        "input_params = np.array([[0.1, 0.1, 0.6, 0.1]])  # Generates random input with 4 dimensions\n",
        "\n",
        "# Generate predictions\n",
        "generated_output = generator.predict(input_params)\n",
        "\n",
        "# Print generated output\n",
        "print(\"Generated Output:\")\n",
        "print(generated_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgoaFI5sHS8r",
        "outputId": "13d60f69-1d09-4ef4-d4ee-b70d6d333d5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 63ms/step\n",
            "Generated Output:\n",
            "[[-0.01115728 -0.03490774 -0.02685214  0.0131126  -0.01353251 -0.03837894]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0PUO4PxpHea7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hkb9mDMRJsu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator Model\n",
        "def build_generator(input_dim, output_dim):\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Dense(128, activation='relu', input_dim=input_dim),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dense(output_dim, activation='linear')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Discriminator Model\n",
        "def build_discriminator(input_dim):\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Dense(512, activation=tf.keras.layers.LeakyReLU(alpha=0.2), input_dim=input_dim),\n",
        "        layers.Dense(256, activation=tf.keras.layers.LeakyReLU(alpha=0.2)),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Hyperparameters\n",
        "z_dim = y.shape[1]  # Dimension of the noise input to the generator, same as output y\n",
        "output_dim = x.shape[1]  # Dimension of output parameters, same as input x\n",
        "\n",
        "# Initialize the models\n",
        "generator = build_generator(z_dim, output_dim)\n",
        "discriminator = build_discriminator(output_dim + z_dim)\n",
        "\n",
        "# Compile the discriminator\n",
        "discriminator.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Build and compile the GAN model\n",
        "discriminator.trainable = False\n",
        "gan_input = layers.Input(shape=(z_dim,))\n",
        "generated_output = generator(gan_input)\n",
        "gan_output = discriminator(tf.concat([generated_output, gan_input], axis=1))\n",
        "gan = tf.keras.models.Model(gan_input, gan_output)\n",
        "gan.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy')\n"
      ],
      "metadata": {
        "id": "0CcDxiioJ1se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "sample_interval = 10\n",
        "\n",
        "# Adversarial ground truths\n",
        "valid = np.ones((batch_size, 1))\n",
        "fake = np.zeros((batch_size, 1))\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # ---------------------\n",
        "    #  Train Discriminator\n",
        "    # ---------------------\n",
        "    # Select a random half batch of real samples\n",
        "    idx = np.random.randint(0, x.shape[0], batch_size)\n",
        "    real_x = x[idx]\n",
        "    real_y = y[idx]\n",
        "\n",
        "    # Generate a half batch of new samples\n",
        "    noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "    gen_x = generator.predict(noise)\n",
        "\n",
        "    # Train the discriminator (real classified as ones and fake as zeros)\n",
        "    d_loss_real = discriminator.train_on_batch(np.hstack((real_x, real_y)), valid)\n",
        "    d_loss_fake = discriminator.train_on_batch(np.hstack((gen_x, noise)), fake)\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "    # ---------------------\n",
        "    #  Train Generator\n",
        "    # ---------------------\n",
        "    # Train the generator (wants discriminator to mistake gen samples as real)\n",
        "    g_loss = gan.train_on_batch(noise, valid)\n",
        "\n",
        "    # If at save interval, print the progress\n",
        "    if epoch % sample_interval == 0:\n",
        "        print(f\"{epoch} [D loss: {d_loss[0]}, acc.: {100*d_loss[1]}] [G loss: {g_loss}]\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8csKNNVqMJnH",
        "outputId": "9ac1ad8c-9c6d-4584-8b91-3fdf670d14b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 36ms/step\n",
            "0 [D loss: 0.3697982244193554, acc.: 85.9375] [G loss: 0.8215440511703491]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "10 [D loss: 0.4134671986103058, acc.: 89.0625] [G loss: 1.0388182401657104]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "20 [D loss: 0.34167711436748505, acc.: 87.5] [G loss: 1.309492588043213]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "30 [D loss: 0.36643774062395096, acc.: 89.0625] [G loss: 1.3292282819747925]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "40 [D loss: 0.3195032700896263, acc.: 89.0625] [G loss: 1.5444884300231934]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "50 [D loss: 0.2703106701374054, acc.: 89.0625] [G loss: 1.7666916847229004]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "60 [D loss: 0.32426895946264267, acc.: 89.0625] [G loss: 1.3413915634155273]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "70 [D loss: 0.31328219547867775, acc.: 87.5] [G loss: 1.3028345108032227]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "80 [D loss: 0.26208077371120453, acc.: 87.5] [G loss: 1.253551721572876]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "90 [D loss: 0.2266897577792406, acc.: 95.3125] [G loss: 1.5463407039642334]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the GAN model\n",
        "generator.save('saved_models/generator_model.h5')\n",
        "discriminator.save('saved_models/discriminator_model.h5')\n",
        "\n",
        "print(\"GAN models saved.\")\n",
        "\n",
        "# Function to load your trained generator model\n",
        "def load_generator_model():\n",
        "    generator = build_generator(input_dim=z_dim, output_dim=output_dim)\n",
        "    generator.load_weights('saved_models/generator_model.h5')  # Adjust path to weights\n",
        "    return generator\n",
        "\n",
        "# Load trained generator model\n",
        "generator = load_generator_model()\n",
        "\n",
        "# Example input with 4 parameters (from y)\n",
        "input_params = np.array([[0.1, 0.2, 0.3, 0.4]])\n",
        "\n",
        "# Generate predictions\n",
        "generated_output = generator.predict(input_params)\n",
        "\n",
        "# Print generated output\n",
        "print(\"Generated Output:\")\n",
        "print(generated_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5rbPVcUMM24",
        "outputId": "11612a0f-25d0-43a6-f3ed-0419cb3111cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GAN models saved.\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "Generated Output:\n",
            "[[-0.242904   -0.09871022  1.7885739  -0.36648172  0.01445589]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EbN8igxMQrZ",
        "outputId": "cbecdf60-aa07-4b74-9ef1-29b2c95a6e73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7.18116144e-06,  8.80420742e-09,  2.00000000e+00,\n",
              "        -1.68000000e+00],\n",
              "       [ 5.37337589e-03,  3.05007199e-08,  1.75000000e+00,\n",
              "        -1.00000000e+00],\n",
              "       [ 6.62965036e-04,  3.68284999e-08,  7.50000000e-01,\n",
              "        -7.50000000e-01],\n",
              "       [ 2.55648537e-04,  5.92684786e-06,  8.77000000e-01,\n",
              "        -1.50000000e+00],\n",
              "       [ 4.06763360e-04,  2.38736774e-05,  5.80000000e-01,\n",
              "        -1.50000000e+00],\n",
              "       [ 6.47202729e-04,  1.11354848e-04,  6.60000000e-01,\n",
              "        -1.50000000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming your x and y are in pandas DataFrame format\n",
        "# x = x.values\n",
        "\n",
        "# y = y.values\n",
        "\n",
        "# # Normalize data if needed\n",
        "# x = (x - x.min()) / (x.max() - x.min())\n",
        "# y = (y - y.min()) / (y.max() - y.min())\n",
        "\n",
        "# x = x.values\n",
        "# y = y.values\n",
        "\n",
        "# Generator Model\n",
        "def build_generator(input_dim, output_dim):\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Dense(64, activation='relu', input_dim=input_dim),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(output_dim, activation='linear')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Discriminator Model\n",
        "def build_discriminator(input_dim):\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Dense(1024, activation=tf.keras.layers.LeakyReLU(alpha=0.2), input_dim=input_dim),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(512, activation=tf.keras.layers.LeakyReLU(alpha=0.2)),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(256, activation=tf.keras.layers.LeakyReLU(alpha=0.2)),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(128, activation=tf.keras.layers.LeakyReLU(alpha=0.2)),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(64, activation=tf.keras.layers.LeakyReLU(alpha=0.2)),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Hyperparameters\n",
        "z_dim = y.shape[1]  # Dimension of the noise input to the generator, same as output y\n",
        "output_dim = x.shape[1]  # Dimension of output parameters, same as input x\n",
        "\n",
        "# Initialize the models\n",
        "generator = build_generator(z_dim, output_dim)\n",
        "discriminator = build_discriminator(output_dim + z_dim)\n",
        "\n",
        "# Compile the discriminator\n",
        "discriminator.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Build and compile the GAN model\n",
        "discriminator.trainable = False\n",
        "gan_input = layers.Input(shape=(z_dim,))\n",
        "generated_output = generator(gan_input)\n",
        "gan_output = discriminator(tf.concat([generated_output, gan_input], axis=1))\n",
        "gan = tf.keras.models.Model(gan_input, gan_output)\n",
        "gan.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy')\n",
        "\n",
        "# Training parameters\n",
        "epochs = 1000\n",
        "batch_size = 32\n",
        "sample_interval = 1000\n",
        "\n",
        "# Adversarial ground truths\n",
        "valid = np.ones((batch_size, 1))\n",
        "fake = np.zeros((batch_size, 1))\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    # Select a random half batch of real samples\n",
        "    idx = np.random.randint(0, x.shape[0], batch_size)\n",
        "    real_x = x[idx]\n",
        "    real_y = y[idx]\n",
        "\n",
        "    # Generate a half batch of new samples\n",
        "    noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "    gen_x = generator.predict(noise)\n",
        "\n",
        "    # Train the discriminator (real classified as ones and fake as zeros)\n",
        "    d_loss_real = discriminator.train_on_batch(np.hstack((real_x, real_y)), valid)\n",
        "    d_loss_fake = discriminator.train_on_batch(np.hstack((gen_x, noise)), fake)\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "    # Train the generator (wants discriminator to mistake gen samples as real)\n",
        "    g_loss = gan.train_on_batch(noise, valid)\n",
        "\n",
        "    # If at save interval, print the progress\n",
        "    if epoch % sample_interval == 0:\n",
        "        print(f\"{epoch} [D loss: {d_loss[0]}, acc.: {100*d_loss[1]}] [G loss: {g_loss}]\")\n",
        "\n",
        "# Save the GAN model\n",
        "generator.save('saved_models/generator_model.h5')\n",
        "discriminator.save('saved_models/discriminator_model.h5')\n",
        "\n",
        "print(\"GAN models saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83gSYT8FMaLk",
        "outputId": "c060c396-54e0-4250-a86f-a68538e9a657"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "0 [D loss: 0.578970342874527, acc.: 46.875] [G loss: 0.6491142511367798]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GAN models saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load your trained generator model\n",
        "def load_generator_model():\n",
        "    generator = build_generator(input_dim=z_dim, output_dim=output_dim)\n",
        "    generator.load_weights('saved_models/generator_model.h5')  # Adjust path to weights\n",
        "    return generator\n",
        "\n",
        "# Load trained generator model\n",
        "generator = load_generator_model()\n",
        "\n",
        "# Example input with 4 parameters (from y)\n",
        "input_params = np.array([[0.01, 5]])\n",
        "\n",
        "# Generate predictions\n",
        "generated_output = generator.predict(input_params)\n",
        "\n",
        "# Print generated output\n",
        "print(\"Generated Output:\")\n",
        "print(generated_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhwq9Rgjf7qp",
        "outputId": "49fb0a1e-3f70-4fc0-b327-949d3af04ffe"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 194ms/step\n",
            "Generated Output:\n",
            "[[-2.2870421 49.477715 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# INTEGER\n",
        "# Function to load your trained generator model\n",
        "def load_generator_model():\n",
        "    generator = build_generator(input_dim=z_dim, output_dim=output_dim)\n",
        "    generator.load_weights('/content/saved_models/generator_model.h5')  # Adjust path to weights\n",
        "    return generator\n",
        "\n",
        "# Load trained generator model\n",
        "generator = load_generator_model()\n",
        "\n",
        "# Define bounds for post-processing\n",
        "bounds = {\n",
        "    'param1': (0.01,0.04 ),\n",
        "    'param2': (1, 70),\n",
        "}\n",
        "\n",
        "# Example input with 4 parameters (from y)\n",
        "input_params = np.array([[0.1, 0.07]])\n",
        "\n",
        "# Generate predictions\n",
        "generated_output = generator.predict(input_params)\n",
        "\n",
        "# Print generated output\n",
        "print(\"Generated Output:\")\n",
        "print(generated_output)\n",
        "\n",
        "# Function to convert scientific notation to desired format\n",
        "def convert_output(output):\n",
        "    converted_output = np.zeros_like(output)\n",
        "    # Keep the first parameter as is\n",
        "    converted_output[:, 0] = output[:, 0]\n",
        "    # Convert the second parameter to integer\n",
        "    converted_output[:, 1] = int(round(output[:, 1].item()))\n",
        "    return converted_output\n",
        "\n",
        "# Convert the generated output\n",
        "converted_output = convert_output(generated_output)\n",
        "\n",
        "# Print converted output\n",
        "print(\"Rounded Output:\")\n",
        "print(converted_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3r_6VCYyhwzD",
        "outputId": "594c1e89-2a7e-4e7f-ea1d-370f3583b423"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 191ms/step\n",
            "Generated Output:\n",
            "[[-0.20300877  4.510864  ]]\n",
            "Rounded Output:\n",
            "[[-0.20300877  5.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gan.summary()\n",
        "discriminator.summary()\n",
        "generator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRCTxM1mtp58",
        "outputId": "941916b3-8cf2-44ec-fc5e-60e92a2deb27"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 2)]                  0         []                            \n",
            "                                                                                                  \n",
            " sequential_8 (Sequential)   (None, 2)                    244802    ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " tf.concat_2 (TFOpLambda)    (None, 4)                    0         ['sequential_8[0][0]',        \n",
            "                                                                     'input_3[0][0]']             \n",
            "                                                                                                  \n",
            " sequential_9 (Sequential)   (None, 1)                    702465    ['tf.concat_2[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 947267 (3.61 MB)\n",
            "Trainable params: 242370 (946.76 KB)\n",
            "Non-trainable params: 704897 (2.69 MB)\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_60 (Dense)            (None, 1024)              5120      \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_64 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_65 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 702465 (2.68 MB)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 702465 (2.68 MB)\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_72 (Dense)            (None, 64)                192       \n",
            "                                                                 \n",
            " batch_normalization_38 (Ba  (None, 64)                256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_50 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " batch_normalization_39 (Ba  (None, 128)               512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_51 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 256)               33024     \n",
            "                                                                 \n",
            " batch_normalization_40 (Ba  (None, 256)               1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_52 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_75 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " batch_normalization_41 (Ba  (None, 256)               1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_53 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_76 (Dense)            (None, 512)               131584    \n",
            "                                                                 \n",
            " batch_normalization_42 (Ba  (None, 512)               2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_54 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_77 (Dense)            (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 244802 (956.26 KB)\n",
            "Trainable params: 242370 (946.76 KB)\n",
            "Non-trainable params: 2432 (9.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define bounds for post-processing\n",
        "bounds = {\n",
        "    'defect_density': (-1, 1),\n",
        "    'no_of_defects': (1, 5)\n",
        "}\n",
        "\n",
        "# Function to post-process the generated samples\n",
        "def post_process_samples(samples, bounds):\n",
        "    processed_samples = np.zeros_like(samples)\n",
        "    processed_samples[:, 0] = np.clip(samples[:, 0], bounds['defect_density'][0], bounds['defect_density'][1])\n",
        "    processed_samples[:, 1] = np.clip(np.round(samples[:, 1]), bounds['no_of_defects'][0], bounds['no_of_defects'][1])\n",
        "    return processed_samples\n",
        "\n",
        "# Example input with 2 parameters (from y)\n",
        "input_params = np.array([[0.1, 0.07]])  # This should match the shape of your output `y`\n",
        "\n",
        "# Generate predictions\n",
        "generated_output = generator.predict(input_params)\n",
        "\n",
        "# Post-process the generated output\n",
        "processed_output = post_process_samples(generated_output, bounds)\n",
        "\n",
        "# Print generated output\n",
        "print(\"Generated Output:\")\n",
        "print(processed_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vMJaHlMDOE2",
        "outputId": "3a4002f7-caad-417f-acac-846aa96dfe52"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 41ms/step\n",
            "Generated Output:\n",
            "[[-0.20300877  5.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions for evaluation\n",
        "import math\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "noise = np.random.normal(0, 1, (x.shape[0], z_dim))\n",
        "generated_output = generator.predict(noise)\n",
        "processed_output = post_process_samples(generated_output, bounds)\n",
        "\n",
        "# Evaluate the performance metrics\n",
        "def compute_metrics(true_data, predicted_data):\n",
        "    metrics = {}\n",
        "    metrics['MAE'] = mean_absolute_error(true_data, predicted_data)\n",
        "    metrics['MSE'] = mean_squared_error(true_data, predicted_data)\n",
        "    metrics['RMSE'] = math.sqrt(metrics['MSE'])\n",
        "    return metrics\n",
        "\n",
        "metrics = compute_metrics(x, processed_output)\n",
        "print(\"Performance Metrics:\")\n",
        "print(f\"MAE: {metrics['MAE']:.6f}\")\n",
        "print(f\"MSE: {metrics['MSE']:.6f}\")\n",
        "print(f\"RMSE: {metrics['RMSE']:.6f}\")"
      ],
      "metadata": {
        "id": "HiOHcrkDuuoS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba39494f-a4b9-491a-c4d0-de965add8a98"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 22ms/step\n",
            "Performance Metrics:\n",
            "MAE: 10.130187\n",
            "MSE: 286.783024\n",
            "RMSE: 16.934669\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from visualkeras import layered_view\n",
        "\n",
        "# # Visualize the generator model\n",
        "# layered_view(generator, legend=True, draw_volume=False).show()\n",
        "\n",
        "# # Visualize the discriminator model\n",
        "# layered_view(discriminator, legend=True, draw_volume=False).show()\n",
        "\n",
        "# # Visualize the GAN model\n",
        "# layered_view(gan, legend=True, draw_volume=False).show()"
      ],
      "metadata": {
        "id": "ENcrhKs2shik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualkeras.layered_view(discriminator , legend=True)"
      ],
      "metadata": {
        "id": "YZgLPlMrspbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOgoowq6kAfA",
        "outputId": "b2d5f67f-3168-43ac-df53-df1fa66e2b9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.1e+01, 6.0e+00, 5.3e-02, 1.0e+00, 2.0e+00, 6.0e+00],\n",
              "       [1.2e+01, 1.0e+00, 1.0e+02, 3.0e+00, 4.0e+00, 0.0e+00],\n",
              "       [1.3e+01, 1.0e+00, 1.0e+02, 3.0e+00, 5.0e+00, 4.0e+00],\n",
              "       [1.4e+01, 3.0e+00, 1.0e+00, 6.0e+00, 1.0e+00, 0.0e+00],\n",
              "       [1.4e+01, 5.0e+00, 1.0e+00, 6.0e+00, 1.0e+00, 0.0e+00],\n",
              "       [1.4e+01, 7.0e+00, 1.0e+00, 6.0e+00, 1.0e+00, 0.0e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp_rVm13uuGF",
        "outputId": "617249fa-f4fc-443c-8166-402b7d059646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7.18116144e-06,  8.80420742e-09,  2.00000000e+00,\n",
              "        -1.68000000e+00],\n",
              "       [ 5.37337589e-03,  3.05007199e-08,  1.75000000e+00,\n",
              "        -1.00000000e+00],\n",
              "       [ 6.62965036e-04,  3.68284999e-08,  7.50000000e-01,\n",
              "        -7.50000000e-01],\n",
              "       [ 2.55648537e-04,  5.92684786e-06,  8.77000000e-01,\n",
              "        -1.50000000e+00],\n",
              "       [ 4.06763360e-04,  2.38736774e-05,  5.80000000e-01,\n",
              "        -1.50000000e+00],\n",
              "       [ 6.47202729e-04,  1.11354848e-04,  6.60000000e-01,\n",
              "        -1.50000000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}